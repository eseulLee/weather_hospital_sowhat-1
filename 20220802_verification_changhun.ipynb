{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e2045f9",
   "metadata": {},
   "source": [
    "# 2012-2015년 데이터로 모델 만들기(남자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b449d375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e57fe7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>772718</td>\n",
       "      <td>12.460044</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>65.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1023.886667</td>\n",
       "      <td>30.158333</td>\n",
       "      <td>39.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6020446</td>\n",
       "      <td>7.432174</td>\n",
       "      <td>50.733333</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1024.875000</td>\n",
       "      <td>28.537404</td>\n",
       "      <td>36.1</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1665308</td>\n",
       "      <td>9.179443</td>\n",
       "      <td>44.916667</td>\n",
       "      <td>47.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1022.950000</td>\n",
       "      <td>26.719907</td>\n",
       "      <td>37.4</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1354649</td>\n",
       "      <td>12.336406</td>\n",
       "      <td>52.377778</td>\n",
       "      <td>70.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1023.268000</td>\n",
       "      <td>25.336806</td>\n",
       "      <td>39.5</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>726529</td>\n",
       "      <td>7.679253</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1025.250000</td>\n",
       "      <td>18.958333</td>\n",
       "      <td>35.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>전남</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>953881</td>\n",
       "      <td>16.198981</td>\n",
       "      <td>66.764033</td>\n",
       "      <td>65.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1031.053846</td>\n",
       "      <td>46.708333</td>\n",
       "      <td>42.1</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>전북</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>930255</td>\n",
       "      <td>14.539347</td>\n",
       "      <td>73.750000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1031.300000</td>\n",
       "      <td>72.548882</td>\n",
       "      <td>40.9</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>제주</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>313428</td>\n",
       "      <td>11.063466</td>\n",
       "      <td>59.915541</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1030.792308</td>\n",
       "      <td>56.156250</td>\n",
       "      <td>38.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>충남</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1054439</td>\n",
       "      <td>13.477024</td>\n",
       "      <td>74.725225</td>\n",
       "      <td>55.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1031.513333</td>\n",
       "      <td>79.543252</td>\n",
       "      <td>40.2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24836</th>\n",
       "      <td>충북</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>798896</td>\n",
       "      <td>12.178056</td>\n",
       "      <td>70.658784</td>\n",
       "      <td>55.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1030.850000</td>\n",
       "      <td>74.573958</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24837 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  diff_hum  \\\n",
       "0       강원   1   1        6     772718      12.460044  58.333333      65.0   \n",
       "1       경기   1   1        6    6020446       7.432174  50.733333      27.0   \n",
       "2       경남   1   1        6    1665308       9.179443  44.916667      47.0   \n",
       "3       경북   1   1        6    1354649      12.336406  52.377778      70.0   \n",
       "4       광주   1   1        6     726529       7.679253  75.833333      15.0   \n",
       "...    ...  ..  ..      ...        ...            ...        ...       ...   \n",
       "24832   전남  12  31        3     953881      16.198981  66.764033      65.0   \n",
       "24833   전북  12  31        3     930255      14.539347  73.750000      50.0   \n",
       "24834   제주  12  31        3     313428      11.063466  59.915541      33.0   \n",
       "24835   충남  12  31        3    1054439      13.477024  74.725225      55.0   \n",
       "24836   충북  12  31        3     798896      12.178056  70.658784      55.0   \n",
       "\n",
       "       diff_temp       avg_ps    pm10_7b  avg_age  min_temp  frequency  \n",
       "0           12.3  1023.886667  30.158333     39.4      -7.3        3.0  \n",
       "1            7.9  1024.875000  28.537404     36.1      -6.9        4.0  \n",
       "2            9.9  1022.950000  26.719907     37.4      -2.9        2.0  \n",
       "3           12.0  1023.268000  25.336806     39.5      -5.9        6.0  \n",
       "4            3.9  1025.250000  18.958333     35.3      -0.9        0.0  \n",
       "...          ...          ...        ...      ...       ...        ...  \n",
       "24832       12.3  1031.053846  46.708333     42.1      -2.3        0.0  \n",
       "24833       10.0  1031.300000  72.548882     40.9      -3.0        1.0  \n",
       "24834        4.9  1030.792308  56.156250     38.7       5.4        0.0  \n",
       "24835        9.0  1031.513333  79.543252     40.2      -3.0        0.0  \n",
       "24836       10.1  1030.850000  74.573958     40.0      -4.0        1.0  \n",
       "\n",
       "[24837 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_male = pd.read_csv('./hospital_male_0802_test3.csv', encoding='cp949')\n",
    "dataset_male = dataset_male[dataset_male['yyyy'].astype(str).str.contains('2012|2013|2014|2015')].reset_index(drop=True)#2016년 전만 추출\n",
    "# dataset_male.drop(columns=['sex', 'heat_wave','cold_wave'], inplace=True)\n",
    "# dataset_male.to_csv('male_df.csv', encoding='cp949')\n",
    "#이창훈\n",
    "male_df = dataset_male[['area','mm','dd','weekday','total_pop','elderly_ratio',\n",
    "                          'avg_hum','diff_hum','diff_temp','avg_ps','pm10_7b',\n",
    "                          'avg_age','min_temp','frequency']]\n",
    "#     ['area','mm','weekday','heat_wave','cold_wave','total_pop','elderly_ratio',\n",
    "#                           'pm10_7b','diff_hum','diff_temp','avg_ps',\n",
    "#                           'avg_age','min_max_ps', 'avg_hum','frequency']]\n",
    "#이이슬\n",
    "# male_df = dataset_male[['area','mm','weekday','heat_wave','cold_wave','total_pop','elderly_ratio',\n",
    "#                           'pm10_31b','diff_hum','diff_temp','avg_ps',\n",
    "#                           'o3','avg_age','min_max_ps', 'avg_hum','frequency']]\n",
    "# fixed_df = dataset2[['area', 'mm', 'frequency','total_pop', 'elderly_ratio','so2','pm10','rhm_min_avg_dif','min_max_Ta','avg_ps']]\n",
    "male_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc6f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# male_df.to_csv('male_df.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b188228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0     9152\n",
       "1.0     6704\n",
       "2.0     4083\n",
       "3.0     2230\n",
       "4.0     1140\n",
       "5.0      708\n",
       "6.0      370\n",
       "7.0      208\n",
       "8.0      127\n",
       "9.0       66\n",
       "10.0      30\n",
       "11.0      12\n",
       "12.0       5\n",
       "13.0       2\n",
       "Name: frequency, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_df['frequency'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f0cdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3 = male_df.quantile(0.75) # df['국어'].quantile(0.75) 처럼 특정 열만 적용 가능\n",
    "# q1 = male_df.quantile(0.25)\n",
    "\n",
    "# iqr = q3 - q1\n",
    "\n",
    "# def is_freq_outlier(df):\n",
    "#     freq_score = df['frequency']\n",
    "#     if freq_score > 10:\n",
    "# #     if freq_score > q3['frequency'] + 1.5 * iqr['frequency'] or freq_score < q1['frequency'] - 1.5 * iqr['frequency']:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# # apply 함수를 통하여 각 값의 이상치 여부를 찾고 새로운 열에 결과 저장\n",
    "# male_df['freq_outlier'] = male_df.apply(is_freq_outlier, axis = 1) # axis = 1 지정 필수\n",
    "# # female_df[female_df['freq_outlier']==True]\n",
    "# male_df = male_df.drop(male_df[male_df['freq_outlier']==True].index, axis=0)\n",
    "# male_df.drop(columns=['freq_outlier'], inplace=True)\n",
    "# male_df.reset_index(drop=True, inplace=True)\n",
    "# male_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2feb07c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (19870, 14)\n",
      "Unseen Data For Predictions: (4967, 14)\n"
     ]
    }
   ],
   "source": [
    "male_data = male_df.sample(frac=0.8, random_state=786) \n",
    "male_data_unseen = male_df.drop(male_data.index) \n",
    "\n",
    "male_data.reset_index(drop=True, inplace=True) \n",
    "male_data_unseen.reset_index(drop=True, inplace=True) \n",
    "\n",
    "print('Data for Modeling: ' + str(male_data.shape)) \n",
    "print('Unseen Data For Predictions: ' + str(male_data_unseen.shape)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2272a",
   "metadata": {},
   "source": [
    "## 모델 환경 설정 (Settinf up Environment in PyCaret)\n",
    "\n",
    "- pycaret을 사용하기 전에 pycaret에 맞게 데이터를 설정\n",
    "- set_up() 함수를 사용\n",
    "- 기본적으로 data와 target을 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d0340f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f7dbd_row8_col1, #T_f7dbd_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f7dbd\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7dbd_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_f7dbd_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7dbd_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_f7dbd_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7dbd_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_f7dbd_row1_col1\" class=\"data row1 col1\" >frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7dbd_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_f7dbd_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7dbd_row3_col0\" class=\"data row3 col0\" >Data shape</td>\n",
       "      <td id=\"T_f7dbd_row3_col1\" class=\"data row3 col1\" >(19870, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f7dbd_row4_col0\" class=\"data row4 col0\" >Train data shape</td>\n",
       "      <td id=\"T_f7dbd_row4_col1\" class=\"data row4 col1\" >(13908, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_f7dbd_row5_col0\" class=\"data row5 col0\" >Test data shape</td>\n",
       "      <td id=\"T_f7dbd_row5_col1\" class=\"data row5 col1\" >(5962, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_f7dbd_row6_col0\" class=\"data row6 col0\" >Numeric features</td>\n",
       "      <td id=\"T_f7dbd_row6_col1\" class=\"data row6 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_f7dbd_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
       "      <td id=\"T_f7dbd_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_f7dbd_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_f7dbd_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_f7dbd_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_f7dbd_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_f7dbd_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_f7dbd_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_f7dbd_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_f7dbd_row11_col1\" class=\"data row11 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_f7dbd_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_f7dbd_row12_col1\" class=\"data row12 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_f7dbd_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
       "      <td id=\"T_f7dbd_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_f7dbd_row14_col0\" class=\"data row14 col0\" >Low variance threshold</td>\n",
       "      <td id=\"T_f7dbd_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_f7dbd_row15_col0\" class=\"data row15 col0\" >Remove multicollinearity</td>\n",
       "      <td id=\"T_f7dbd_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_f7dbd_row16_col0\" class=\"data row16 col0\" >Multicollinearity threshold</td>\n",
       "      <td id=\"T_f7dbd_row16_col1\" class=\"data row16 col1\" >0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_f7dbd_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_f7dbd_row17_col1\" class=\"data row17 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_f7dbd_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_f7dbd_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_f7dbd_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_f7dbd_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_f7dbd_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_f7dbd_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_f7dbd_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_f7dbd_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_f7dbd_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_f7dbd_row22_col1\" class=\"data row22 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7dbd_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_f7dbd_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_f7dbd_row23_col1\" class=\"data row23 col1\" >a7a8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1573ad370>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 자동으로 데이터 유형 지정 \n",
    "from pycaret.regression import *\n",
    "male_data_s = setup(male_data, target = 'frequency', session_id=123, categorical_features=['area','mm','weekday',\n",
    "#                                                                                            'heat_wave','cold_wave'\n",
    "                                                                                          ],\n",
    "         remove_multicollinearity = True, multicollinearity_threshold = 0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79b2715",
   "metadata": {},
   "source": [
    "#### set_up(): pycaret을 사용하기 위한 data setting\n",
    "\n",
    "- session_id: random_state와 같은 개념으로 같은 결과가 나올 수 있게 seed를 고정\n",
    "- data: train 데이터 입력\n",
    "- target = target 변수 이름을 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268e409",
   "metadata": {},
   "source": [
    "## 모델 생성 - 비교\n",
    "\n",
    "- 여러 모델을 적합하여 성능을 비교하는 단계\n",
    "- compare_models(): 다양한 모델 적합 후 성능 비교\n",
    "    - fold: cross_validation의 fold를 지정 (default = 10)\n",
    "    - sort: 정렬기준 지표 설정\n",
    "    - n_select: 상위 n개의 모델 결과만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69a93174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5eda1 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5eda1_row0_col0, #T_5eda1_row0_col1, #T_5eda1_row0_col6, #T_5eda1_row1_col0, #T_5eda1_row1_col1, #T_5eda1_row1_col2, #T_5eda1_row1_col3, #T_5eda1_row1_col5, #T_5eda1_row1_col6, #T_5eda1_row2_col0, #T_5eda1_row2_col1, #T_5eda1_row2_col2, #T_5eda1_row2_col3, #T_5eda1_row2_col5, #T_5eda1_row2_col6, #T_5eda1_row3_col0, #T_5eda1_row3_col1, #T_5eda1_row3_col2, #T_5eda1_row3_col3, #T_5eda1_row3_col5, #T_5eda1_row3_col6, #T_5eda1_row4_col0, #T_5eda1_row4_col1, #T_5eda1_row4_col2, #T_5eda1_row4_col3, #T_5eda1_row4_col4, #T_5eda1_row4_col5, #T_5eda1_row4_col6, #T_5eda1_row5_col0, #T_5eda1_row5_col1, #T_5eda1_row5_col2, #T_5eda1_row5_col3, #T_5eda1_row5_col4, #T_5eda1_row5_col5, #T_5eda1_row5_col6, #T_5eda1_row6_col0, #T_5eda1_row6_col1, #T_5eda1_row6_col2, #T_5eda1_row6_col3, #T_5eda1_row6_col4, #T_5eda1_row6_col5, #T_5eda1_row6_col6, #T_5eda1_row7_col0, #T_5eda1_row7_col1, #T_5eda1_row7_col2, #T_5eda1_row7_col3, #T_5eda1_row7_col4, #T_5eda1_row7_col5, #T_5eda1_row7_col6, #T_5eda1_row8_col0, #T_5eda1_row8_col1, #T_5eda1_row8_col2, #T_5eda1_row8_col3, #T_5eda1_row8_col4, #T_5eda1_row8_col5, #T_5eda1_row8_col6, #T_5eda1_row9_col0, #T_5eda1_row9_col1, #T_5eda1_row9_col2, #T_5eda1_row9_col3, #T_5eda1_row9_col4, #T_5eda1_row9_col5, #T_5eda1_row9_col6, #T_5eda1_row10_col0, #T_5eda1_row10_col2, #T_5eda1_row10_col3, #T_5eda1_row10_col4, #T_5eda1_row10_col5, #T_5eda1_row10_col6, #T_5eda1_row11_col0, #T_5eda1_row11_col1, #T_5eda1_row11_col2, #T_5eda1_row11_col3, #T_5eda1_row11_col4, #T_5eda1_row11_col5, #T_5eda1_row12_col0, #T_5eda1_row12_col1, #T_5eda1_row12_col2, #T_5eda1_row12_col3, #T_5eda1_row12_col4, #T_5eda1_row12_col5, #T_5eda1_row12_col6, #T_5eda1_row13_col0, #T_5eda1_row13_col1, #T_5eda1_row13_col2, #T_5eda1_row13_col3, #T_5eda1_row13_col4, #T_5eda1_row13_col5, #T_5eda1_row13_col6, #T_5eda1_row14_col0, #T_5eda1_row14_col1, #T_5eda1_row14_col2, #T_5eda1_row14_col3, #T_5eda1_row14_col4, #T_5eda1_row14_col5, #T_5eda1_row14_col6, #T_5eda1_row15_col0, #T_5eda1_row15_col1, #T_5eda1_row15_col2, #T_5eda1_row15_col3, #T_5eda1_row15_col4, #T_5eda1_row15_col5, #T_5eda1_row15_col6, #T_5eda1_row16_col0, #T_5eda1_row16_col1, #T_5eda1_row16_col2, #T_5eda1_row16_col3, #T_5eda1_row16_col4, #T_5eda1_row16_col5, #T_5eda1_row16_col6, #T_5eda1_row17_col0, #T_5eda1_row17_col1, #T_5eda1_row17_col2, #T_5eda1_row17_col3, #T_5eda1_row17_col4, #T_5eda1_row17_col5, #T_5eda1_row17_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_5eda1_row0_col2, #T_5eda1_row0_col3, #T_5eda1_row0_col4, #T_5eda1_row0_col5, #T_5eda1_row1_col4, #T_5eda1_row2_col4, #T_5eda1_row3_col4, #T_5eda1_row10_col1, #T_5eda1_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_5eda1_row0_col7, #T_5eda1_row1_col7, #T_5eda1_row2_col7, #T_5eda1_row4_col7, #T_5eda1_row5_col7, #T_5eda1_row6_col7, #T_5eda1_row7_col7, #T_5eda1_row8_col7, #T_5eda1_row9_col7, #T_5eda1_row10_col7, #T_5eda1_row11_col7, #T_5eda1_row12_col7, #T_5eda1_row13_col7, #T_5eda1_row14_col7, #T_5eda1_row15_col7, #T_5eda1_row16_col7, #T_5eda1_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_5eda1_row3_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5eda1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5eda1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_5eda1_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_5eda1_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_5eda1_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_5eda1_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_5eda1_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_5eda1_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_5eda1_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row0\" class=\"row_heading level0 row0\" >br</th>\n",
       "      <td id=\"T_5eda1_row0_col0\" class=\"data row0 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_5eda1_row0_col1\" class=\"data row0 col1\" >0.9101</td>\n",
       "      <td id=\"T_5eda1_row0_col2\" class=\"data row0 col2\" >1.5444</td>\n",
       "      <td id=\"T_5eda1_row0_col3\" class=\"data row0 col3\" >1.2422</td>\n",
       "      <td id=\"T_5eda1_row0_col4\" class=\"data row0 col4\" >0.4716</td>\n",
       "      <td id=\"T_5eda1_row0_col5\" class=\"data row0 col5\" >0.4864</td>\n",
       "      <td id=\"T_5eda1_row0_col6\" class=\"data row0 col6\" >0.4522</td>\n",
       "      <td id=\"T_5eda1_row0_col7\" class=\"data row0 col7\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_5eda1_row1_col0\" class=\"data row1 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_5eda1_row1_col1\" class=\"data row1 col1\" >0.9104</td>\n",
       "      <td id=\"T_5eda1_row1_col2\" class=\"data row1 col2\" >1.5445</td>\n",
       "      <td id=\"T_5eda1_row1_col3\" class=\"data row1 col3\" >1.2423</td>\n",
       "      <td id=\"T_5eda1_row1_col4\" class=\"data row1 col4\" >0.4716</td>\n",
       "      <td id=\"T_5eda1_row1_col5\" class=\"data row1 col5\" >0.4865</td>\n",
       "      <td id=\"T_5eda1_row1_col6\" class=\"data row1 col6\" >0.4527</td>\n",
       "      <td id=\"T_5eda1_row1_col7\" class=\"data row1 col7\" >0.2320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_5eda1_row2_col0\" class=\"data row2 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_5eda1_row2_col1\" class=\"data row2 col1\" >0.9103</td>\n",
       "      <td id=\"T_5eda1_row2_col2\" class=\"data row2 col2\" >1.5445</td>\n",
       "      <td id=\"T_5eda1_row2_col3\" class=\"data row2 col3\" >1.2423</td>\n",
       "      <td id=\"T_5eda1_row2_col4\" class=\"data row2 col4\" >0.4716</td>\n",
       "      <td id=\"T_5eda1_row2_col5\" class=\"data row2 col5\" >0.4865</td>\n",
       "      <td id=\"T_5eda1_row2_col6\" class=\"data row2 col6\" >0.4526</td>\n",
       "      <td id=\"T_5eda1_row2_col7\" class=\"data row2 col7\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row3\" class=\"row_heading level0 row3\" >lar</th>\n",
       "      <td id=\"T_5eda1_row3_col0\" class=\"data row3 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_5eda1_row3_col1\" class=\"data row3 col1\" >0.9104</td>\n",
       "      <td id=\"T_5eda1_row3_col2\" class=\"data row3 col2\" >1.5445</td>\n",
       "      <td id=\"T_5eda1_row3_col3\" class=\"data row3 col3\" >1.2423</td>\n",
       "      <td id=\"T_5eda1_row3_col4\" class=\"data row3 col4\" >0.4716</td>\n",
       "      <td id=\"T_5eda1_row3_col5\" class=\"data row3 col5\" >0.4865</td>\n",
       "      <td id=\"T_5eda1_row3_col6\" class=\"data row3 col6\" >0.4527</td>\n",
       "      <td id=\"T_5eda1_row3_col7\" class=\"data row3 col7\" >0.0160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row4\" class=\"row_heading level0 row4\" >omp</th>\n",
       "      <td id=\"T_5eda1_row4_col0\" class=\"data row4 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_5eda1_row4_col1\" class=\"data row4 col1\" >0.9118</td>\n",
       "      <td id=\"T_5eda1_row4_col2\" class=\"data row4 col2\" >1.5891</td>\n",
       "      <td id=\"T_5eda1_row4_col3\" class=\"data row4 col3\" >1.2601</td>\n",
       "      <td id=\"T_5eda1_row4_col4\" class=\"data row4 col4\" >0.4563</td>\n",
       "      <td id=\"T_5eda1_row4_col5\" class=\"data row4 col5\" >0.4888</td>\n",
       "      <td id=\"T_5eda1_row4_col6\" class=\"data row4 col6\" >0.4419</td>\n",
       "      <td id=\"T_5eda1_row4_col7\" class=\"data row4 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_5eda1_row5_col0\" class=\"data row5 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_5eda1_row5_col1\" class=\"data row5 col1\" >0.9317</td>\n",
       "      <td id=\"T_5eda1_row5_col2\" class=\"data row5 col2\" >1.5995</td>\n",
       "      <td id=\"T_5eda1_row5_col3\" class=\"data row5 col3\" >1.2641</td>\n",
       "      <td id=\"T_5eda1_row5_col4\" class=\"data row5 col4\" >0.4530</td>\n",
       "      <td id=\"T_5eda1_row5_col5\" class=\"data row5 col5\" >0.4984</td>\n",
       "      <td id=\"T_5eda1_row5_col6\" class=\"data row5 col6\" >0.4522</td>\n",
       "      <td id=\"T_5eda1_row5_col7\" class=\"data row5 col7\" >0.1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row6\" class=\"row_heading level0 row6\" >rf</th>\n",
       "      <td id=\"T_5eda1_row6_col0\" class=\"data row6 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_5eda1_row6_col1\" class=\"data row6 col1\" >0.8994</td>\n",
       "      <td id=\"T_5eda1_row6_col2\" class=\"data row6 col2\" >1.6417</td>\n",
       "      <td id=\"T_5eda1_row6_col3\" class=\"data row6 col3\" >1.2808</td>\n",
       "      <td id=\"T_5eda1_row6_col4\" class=\"data row6 col4\" >0.4383</td>\n",
       "      <td id=\"T_5eda1_row6_col5\" class=\"data row6 col5\" >0.5090</td>\n",
       "      <td id=\"T_5eda1_row6_col6\" class=\"data row6 col6\" >0.4485</td>\n",
       "      <td id=\"T_5eda1_row6_col7\" class=\"data row6 col7\" >0.3570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row7\" class=\"row_heading level0 row7\" >huber</th>\n",
       "      <td id=\"T_5eda1_row7_col0\" class=\"data row7 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_5eda1_row7_col1\" class=\"data row7 col1\" >0.9251</td>\n",
       "      <td id=\"T_5eda1_row7_col2\" class=\"data row7 col2\" >1.6619</td>\n",
       "      <td id=\"T_5eda1_row7_col3\" class=\"data row7 col3\" >1.2885</td>\n",
       "      <td id=\"T_5eda1_row7_col4\" class=\"data row7 col4\" >0.4315</td>\n",
       "      <td id=\"T_5eda1_row7_col5\" class=\"data row7 col5\" >0.4895</td>\n",
       "      <td id=\"T_5eda1_row7_col6\" class=\"data row7 col6\" >0.4420</td>\n",
       "      <td id=\"T_5eda1_row7_col7\" class=\"data row7 col7\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row8\" class=\"row_heading level0 row8\" >gbr</th>\n",
       "      <td id=\"T_5eda1_row8_col0\" class=\"data row8 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_5eda1_row8_col1\" class=\"data row8 col1\" >1.0002</td>\n",
       "      <td id=\"T_5eda1_row8_col2\" class=\"data row8 col2\" >1.6621</td>\n",
       "      <td id=\"T_5eda1_row8_col3\" class=\"data row8 col3\" >1.2889</td>\n",
       "      <td id=\"T_5eda1_row8_col4\" class=\"data row8 col4\" >0.4312</td>\n",
       "      <td id=\"T_5eda1_row8_col5\" class=\"data row8 col5\" >0.5397</td>\n",
       "      <td id=\"T_5eda1_row8_col6\" class=\"data row8 col6\" >0.4306</td>\n",
       "      <td id=\"T_5eda1_row8_col7\" class=\"data row8 col7\" >0.2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row9\" class=\"row_heading level0 row9\" >lightgbm</th>\n",
       "      <td id=\"T_5eda1_row9_col0\" class=\"data row9 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_5eda1_row9_col1\" class=\"data row9 col1\" >0.9763</td>\n",
       "      <td id=\"T_5eda1_row9_col2\" class=\"data row9 col2\" >1.6697</td>\n",
       "      <td id=\"T_5eda1_row9_col3\" class=\"data row9 col3\" >1.2918</td>\n",
       "      <td id=\"T_5eda1_row9_col4\" class=\"data row9 col4\" >0.4286</td>\n",
       "      <td id=\"T_5eda1_row9_col5\" class=\"data row9 col5\" >0.5280</td>\n",
       "      <td id=\"T_5eda1_row9_col6\" class=\"data row9 col6\" >0.4355</td>\n",
       "      <td id=\"T_5eda1_row9_col7\" class=\"data row9 col7\" >0.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_5eda1_row10_col0\" class=\"data row10 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_5eda1_row10_col1\" class=\"data row10 col1\" >0.8939</td>\n",
       "      <td id=\"T_5eda1_row10_col2\" class=\"data row10 col2\" >1.6756</td>\n",
       "      <td id=\"T_5eda1_row10_col3\" class=\"data row10 col3\" >1.2940</td>\n",
       "      <td id=\"T_5eda1_row10_col4\" class=\"data row10 col4\" >0.4267</td>\n",
       "      <td id=\"T_5eda1_row10_col5\" class=\"data row10 col5\" >0.5132</td>\n",
       "      <td id=\"T_5eda1_row10_col6\" class=\"data row10 col6\" >0.4444</td>\n",
       "      <td id=\"T_5eda1_row10_col7\" class=\"data row10 col7\" >0.0210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row11\" class=\"row_heading level0 row11\" >en</th>\n",
       "      <td id=\"T_5eda1_row11_col0\" class=\"data row11 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_5eda1_row11_col1\" class=\"data row11 col1\" >1.0539</td>\n",
       "      <td id=\"T_5eda1_row11_col2\" class=\"data row11 col2\" >1.9841</td>\n",
       "      <td id=\"T_5eda1_row11_col3\" class=\"data row11 col3\" >1.4082</td>\n",
       "      <td id=\"T_5eda1_row11_col4\" class=\"data row11 col4\" >0.3216</td>\n",
       "      <td id=\"T_5eda1_row11_col5\" class=\"data row11 col5\" >0.5499</td>\n",
       "      <td id=\"T_5eda1_row11_col6\" class=\"data row11 col6\" >0.3858</td>\n",
       "      <td id=\"T_5eda1_row11_col7\" class=\"data row11 col7\" >0.0240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row12\" class=\"row_heading level0 row12\" >lasso</th>\n",
       "      <td id=\"T_5eda1_row12_col0\" class=\"data row12 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_5eda1_row12_col1\" class=\"data row12 col1\" >1.1518</td>\n",
       "      <td id=\"T_5eda1_row12_col2\" class=\"data row12 col2\" >2.3378</td>\n",
       "      <td id=\"T_5eda1_row12_col3\" class=\"data row12 col3\" >1.5285</td>\n",
       "      <td id=\"T_5eda1_row12_col4\" class=\"data row12 col4\" >0.2008</td>\n",
       "      <td id=\"T_5eda1_row12_col5\" class=\"data row12 col5\" >0.5907</td>\n",
       "      <td id=\"T_5eda1_row12_col6\" class=\"data row12 col6\" >0.4079</td>\n",
       "      <td id=\"T_5eda1_row12_col7\" class=\"data row12 col7\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row13\" class=\"row_heading level0 row13\" >ada</th>\n",
       "      <td id=\"T_5eda1_row13_col0\" class=\"data row13 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_5eda1_row13_col1\" class=\"data row13 col1\" >1.4623</td>\n",
       "      <td id=\"T_5eda1_row13_col2\" class=\"data row13 col2\" >2.9187</td>\n",
       "      <td id=\"T_5eda1_row13_col3\" class=\"data row13 col3\" >1.7021</td>\n",
       "      <td id=\"T_5eda1_row13_col4\" class=\"data row13 col4\" >0.0058</td>\n",
       "      <td id=\"T_5eda1_row13_col5\" class=\"data row13 col5\" >0.7415</td>\n",
       "      <td id=\"T_5eda1_row13_col6\" class=\"data row13 col6\" >0.7339</td>\n",
       "      <td id=\"T_5eda1_row13_col7\" class=\"data row13 col7\" >0.0940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row14\" class=\"row_heading level0 row14\" >knn</th>\n",
       "      <td id=\"T_5eda1_row14_col0\" class=\"data row14 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_5eda1_row14_col1\" class=\"data row14 col1\" >1.2473</td>\n",
       "      <td id=\"T_5eda1_row14_col2\" class=\"data row14 col2\" >2.9223</td>\n",
       "      <td id=\"T_5eda1_row14_col3\" class=\"data row14 col3\" >1.7087</td>\n",
       "      <td id=\"T_5eda1_row14_col4\" class=\"data row14 col4\" >0.0014</td>\n",
       "      <td id=\"T_5eda1_row14_col5\" class=\"data row14 col5\" >0.6445</td>\n",
       "      <td id=\"T_5eda1_row14_col6\" class=\"data row14 col6\" >0.5403</td>\n",
       "      <td id=\"T_5eda1_row14_col7\" class=\"data row14 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row15\" class=\"row_heading level0 row15\" >llar</th>\n",
       "      <td id=\"T_5eda1_row15_col0\" class=\"data row15 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_5eda1_row15_col1\" class=\"data row15 col1\" >1.2962</td>\n",
       "      <td id=\"T_5eda1_row15_col2\" class=\"data row15 col2\" >2.9277</td>\n",
       "      <td id=\"T_5eda1_row15_col3\" class=\"data row15 col3\" >1.7106</td>\n",
       "      <td id=\"T_5eda1_row15_col4\" class=\"data row15 col4\" >-0.0011</td>\n",
       "      <td id=\"T_5eda1_row15_col5\" class=\"data row15 col5\" >0.6539</td>\n",
       "      <td id=\"T_5eda1_row15_col6\" class=\"data row15 col6\" >0.4577</td>\n",
       "      <td id=\"T_5eda1_row15_col7\" class=\"data row15 col7\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row16\" class=\"row_heading level0 row16\" >dummy</th>\n",
       "      <td id=\"T_5eda1_row16_col0\" class=\"data row16 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_5eda1_row16_col1\" class=\"data row16 col1\" >1.2962</td>\n",
       "      <td id=\"T_5eda1_row16_col2\" class=\"data row16 col2\" >2.9277</td>\n",
       "      <td id=\"T_5eda1_row16_col3\" class=\"data row16 col3\" >1.7106</td>\n",
       "      <td id=\"T_5eda1_row16_col4\" class=\"data row16 col4\" >-0.0011</td>\n",
       "      <td id=\"T_5eda1_row16_col5\" class=\"data row16 col5\" >0.6539</td>\n",
       "      <td id=\"T_5eda1_row16_col6\" class=\"data row16 col6\" >0.4577</td>\n",
       "      <td id=\"T_5eda1_row16_col7\" class=\"data row16 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5eda1_level0_row17\" class=\"row_heading level0 row17\" >par</th>\n",
       "      <td id=\"T_5eda1_row17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_5eda1_row17_col1\" class=\"data row17 col1\" >1.5884</td>\n",
       "      <td id=\"T_5eda1_row17_col2\" class=\"data row17 col2\" >3.8274</td>\n",
       "      <td id=\"T_5eda1_row17_col3\" class=\"data row17 col3\" >1.8761</td>\n",
       "      <td id=\"T_5eda1_row17_col4\" class=\"data row17 col4\" >-0.3157</td>\n",
       "      <td id=\"T_5eda1_row17_col5\" class=\"data row17 col5\" >0.7422</td>\n",
       "      <td id=\"T_5eda1_row17_col6\" class=\"data row17 col6\" >0.8813</td>\n",
       "      <td id=\"T_5eda1_row17_col7\" class=\"data row17 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1573be0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_fece2_row10_col0, #T_fece2_row10_col1, #T_fece2_row10_col2, #T_fece2_row10_col3, #T_fece2_row10_col4, #T_fece2_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_fece2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fece2_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_fece2_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_fece2_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_fece2_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_fece2_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_fece2_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fece2_row0_col0\" class=\"data row0 col0\" >0.8956</td>\n",
       "      <td id=\"T_fece2_row0_col1\" class=\"data row0 col1\" >1.4795</td>\n",
       "      <td id=\"T_fece2_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_fece2_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_fece2_row0_col4\" class=\"data row0 col4\" >0.4883</td>\n",
       "      <td id=\"T_fece2_row0_col5\" class=\"data row0 col5\" >0.4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fece2_row1_col0\" class=\"data row1 col0\" >0.9421</td>\n",
       "      <td id=\"T_fece2_row1_col1\" class=\"data row1 col1\" >1.6872</td>\n",
       "      <td id=\"T_fece2_row1_col2\" class=\"data row1 col2\" >1.2989</td>\n",
       "      <td id=\"T_fece2_row1_col3\" class=\"data row1 col3\" >0.4672</td>\n",
       "      <td id=\"T_fece2_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_fece2_row1_col5\" class=\"data row1 col5\" >0.4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fece2_row2_col0\" class=\"data row2 col0\" >0.9267</td>\n",
       "      <td id=\"T_fece2_row2_col1\" class=\"data row2 col1\" >1.5773</td>\n",
       "      <td id=\"T_fece2_row2_col2\" class=\"data row2 col2\" >1.2559</td>\n",
       "      <td id=\"T_fece2_row2_col3\" class=\"data row2 col3\" >0.4531</td>\n",
       "      <td id=\"T_fece2_row2_col4\" class=\"data row2 col4\" >0.4916</td>\n",
       "      <td id=\"T_fece2_row2_col5\" class=\"data row2 col5\" >0.4814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fece2_row3_col0\" class=\"data row3 col0\" >0.8826</td>\n",
       "      <td id=\"T_fece2_row3_col1\" class=\"data row3 col1\" >1.4339</td>\n",
       "      <td id=\"T_fece2_row3_col2\" class=\"data row3 col2\" >1.1974</td>\n",
       "      <td id=\"T_fece2_row3_col3\" class=\"data row3 col3\" >0.4855</td>\n",
       "      <td id=\"T_fece2_row3_col4\" class=\"data row3 col4\" >0.4822</td>\n",
       "      <td id=\"T_fece2_row3_col5\" class=\"data row3 col5\" >0.4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fece2_row4_col0\" class=\"data row4 col0\" >0.8739</td>\n",
       "      <td id=\"T_fece2_row4_col1\" class=\"data row4 col1\" >1.4666</td>\n",
       "      <td id=\"T_fece2_row4_col2\" class=\"data row4 col2\" >1.2110</td>\n",
       "      <td id=\"T_fece2_row4_col3\" class=\"data row4 col3\" >0.5154</td>\n",
       "      <td id=\"T_fece2_row4_col4\" class=\"data row4 col4\" >0.4620</td>\n",
       "      <td id=\"T_fece2_row4_col5\" class=\"data row4 col5\" >0.4305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_fece2_row5_col0\" class=\"data row5 col0\" >0.9147</td>\n",
       "      <td id=\"T_fece2_row5_col1\" class=\"data row5 col1\" >1.5874</td>\n",
       "      <td id=\"T_fece2_row5_col2\" class=\"data row5 col2\" >1.2599</td>\n",
       "      <td id=\"T_fece2_row5_col3\" class=\"data row5 col3\" >0.4883</td>\n",
       "      <td id=\"T_fece2_row5_col4\" class=\"data row5 col4\" >0.4873</td>\n",
       "      <td id=\"T_fece2_row5_col5\" class=\"data row5 col5\" >0.4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_fece2_row6_col0\" class=\"data row6 col0\" >0.8939</td>\n",
       "      <td id=\"T_fece2_row6_col1\" class=\"data row6 col1\" >1.5073</td>\n",
       "      <td id=\"T_fece2_row6_col2\" class=\"data row6 col2\" >1.2277</td>\n",
       "      <td id=\"T_fece2_row6_col3\" class=\"data row6 col3\" >0.4792</td>\n",
       "      <td id=\"T_fece2_row6_col4\" class=\"data row6 col4\" >0.4881</td>\n",
       "      <td id=\"T_fece2_row6_col5\" class=\"data row6 col5\" >0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_fece2_row7_col0\" class=\"data row7 col0\" >0.9257</td>\n",
       "      <td id=\"T_fece2_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_fece2_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_fece2_row7_col3\" class=\"data row7 col3\" >0.4362</td>\n",
       "      <td id=\"T_fece2_row7_col4\" class=\"data row7 col4\" >0.4990</td>\n",
       "      <td id=\"T_fece2_row7_col5\" class=\"data row7 col5\" >0.4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_fece2_row8_col0\" class=\"data row8 col0\" >0.9600</td>\n",
       "      <td id=\"T_fece2_row8_col1\" class=\"data row8 col1\" >1.6901</td>\n",
       "      <td id=\"T_fece2_row8_col2\" class=\"data row8 col2\" >1.3000</td>\n",
       "      <td id=\"T_fece2_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_fece2_row8_col4\" class=\"data row8 col4\" >0.5109</td>\n",
       "      <td id=\"T_fece2_row8_col5\" class=\"data row8 col5\" >0.4774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_fece2_row9_col0\" class=\"data row9 col0\" >0.8855</td>\n",
       "      <td id=\"T_fece2_row9_col1\" class=\"data row9 col1\" >1.4704</td>\n",
       "      <td id=\"T_fece2_row9_col2\" class=\"data row9 col2\" >1.2126</td>\n",
       "      <td id=\"T_fece2_row9_col3\" class=\"data row9 col3\" >0.4907</td>\n",
       "      <td id=\"T_fece2_row9_col4\" class=\"data row9 col4\" >0.4747</td>\n",
       "      <td id=\"T_fece2_row9_col5\" class=\"data row9 col5\" >0.4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_fece2_row10_col0\" class=\"data row10 col0\" >0.9101</td>\n",
       "      <td id=\"T_fece2_row10_col1\" class=\"data row10 col1\" >1.5444</td>\n",
       "      <td id=\"T_fece2_row10_col2\" class=\"data row10 col2\" >1.2422</td>\n",
       "      <td id=\"T_fece2_row10_col3\" class=\"data row10 col3\" >0.4716</td>\n",
       "      <td id=\"T_fece2_row10_col4\" class=\"data row10 col4\" >0.4864</td>\n",
       "      <td id=\"T_fece2_row10_col5\" class=\"data row10 col5\" >0.4522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fece2_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_fece2_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_fece2_row11_col1\" class=\"data row11 col1\" >0.0860</td>\n",
       "      <td id=\"T_fece2_row11_col2\" class=\"data row11 col2\" >0.0343</td>\n",
       "      <td id=\"T_fece2_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_fece2_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_fece2_row11_col5\" class=\"data row11 col5\" >0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1572adeb0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e4e56_row10_col0, #T_e4e56_row10_col1, #T_e4e56_row10_col2, #T_e4e56_row10_col3, #T_e4e56_row10_col4, #T_e4e56_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e4e56\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e4e56_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_e4e56_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_e4e56_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_e4e56_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_e4e56_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_e4e56_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e4e56_row0_col0\" class=\"data row0 col0\" >0.8958</td>\n",
       "      <td id=\"T_e4e56_row0_col1\" class=\"data row0 col1\" >1.4796</td>\n",
       "      <td id=\"T_e4e56_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_e4e56_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_e4e56_row0_col4\" class=\"data row0 col4\" >0.4884</td>\n",
       "      <td id=\"T_e4e56_row0_col5\" class=\"data row0 col5\" >0.4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e4e56_row1_col0\" class=\"data row1 col0\" >0.9425</td>\n",
       "      <td id=\"T_e4e56_row1_col1\" class=\"data row1 col1\" >1.6873</td>\n",
       "      <td id=\"T_e4e56_row1_col2\" class=\"data row1 col2\" >1.2989</td>\n",
       "      <td id=\"T_e4e56_row1_col3\" class=\"data row1 col3\" >0.4672</td>\n",
       "      <td id=\"T_e4e56_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_e4e56_row1_col5\" class=\"data row1 col5\" >0.4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_e4e56_row2_col0\" class=\"data row2 col0\" >0.9270</td>\n",
       "      <td id=\"T_e4e56_row2_col1\" class=\"data row2 col1\" >1.5778</td>\n",
       "      <td id=\"T_e4e56_row2_col2\" class=\"data row2 col2\" >1.2561</td>\n",
       "      <td id=\"T_e4e56_row2_col3\" class=\"data row2 col3\" >0.4529</td>\n",
       "      <td id=\"T_e4e56_row2_col4\" class=\"data row2 col4\" >0.4917</td>\n",
       "      <td id=\"T_e4e56_row2_col5\" class=\"data row2 col5\" >0.4819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_e4e56_row3_col0\" class=\"data row3 col0\" >0.8829</td>\n",
       "      <td id=\"T_e4e56_row3_col1\" class=\"data row3 col1\" >1.4339</td>\n",
       "      <td id=\"T_e4e56_row3_col2\" class=\"data row3 col2\" >1.1975</td>\n",
       "      <td id=\"T_e4e56_row3_col3\" class=\"data row3 col3\" >0.4855</td>\n",
       "      <td id=\"T_e4e56_row3_col4\" class=\"data row3 col4\" >0.4823</td>\n",
       "      <td id=\"T_e4e56_row3_col5\" class=\"data row3 col5\" >0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_e4e56_row4_col0\" class=\"data row4 col0\" >0.8742</td>\n",
       "      <td id=\"T_e4e56_row4_col1\" class=\"data row4 col1\" >1.4666</td>\n",
       "      <td id=\"T_e4e56_row4_col2\" class=\"data row4 col2\" >1.2110</td>\n",
       "      <td id=\"T_e4e56_row4_col3\" class=\"data row4 col3\" >0.5154</td>\n",
       "      <td id=\"T_e4e56_row4_col4\" class=\"data row4 col4\" >0.4621</td>\n",
       "      <td id=\"T_e4e56_row4_col5\" class=\"data row4 col5\" >0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_e4e56_row5_col0\" class=\"data row5 col0\" >0.9150</td>\n",
       "      <td id=\"T_e4e56_row5_col1\" class=\"data row5 col1\" >1.5874</td>\n",
       "      <td id=\"T_e4e56_row5_col2\" class=\"data row5 col2\" >1.2599</td>\n",
       "      <td id=\"T_e4e56_row5_col3\" class=\"data row5 col3\" >0.4883</td>\n",
       "      <td id=\"T_e4e56_row5_col4\" class=\"data row5 col4\" >0.4874</td>\n",
       "      <td id=\"T_e4e56_row5_col5\" class=\"data row5 col5\" >0.4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_e4e56_row6_col0\" class=\"data row6 col0\" >0.8941</td>\n",
       "      <td id=\"T_e4e56_row6_col1\" class=\"data row6 col1\" >1.5075</td>\n",
       "      <td id=\"T_e4e56_row6_col2\" class=\"data row6 col2\" >1.2278</td>\n",
       "      <td id=\"T_e4e56_row6_col3\" class=\"data row6 col3\" >0.4792</td>\n",
       "      <td id=\"T_e4e56_row6_col4\" class=\"data row6 col4\" >0.4882</td>\n",
       "      <td id=\"T_e4e56_row6_col5\" class=\"data row6 col5\" >0.4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_e4e56_row7_col0\" class=\"data row7 col0\" >0.9260</td>\n",
       "      <td id=\"T_e4e56_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_e4e56_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_e4e56_row7_col3\" class=\"data row7 col3\" >0.4361</td>\n",
       "      <td id=\"T_e4e56_row7_col4\" class=\"data row7 col4\" >0.4991</td>\n",
       "      <td id=\"T_e4e56_row7_col5\" class=\"data row7 col5\" >0.4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_e4e56_row8_col0\" class=\"data row8 col0\" >0.9603</td>\n",
       "      <td id=\"T_e4e56_row8_col1\" class=\"data row8 col1\" >1.6902</td>\n",
       "      <td id=\"T_e4e56_row8_col2\" class=\"data row8 col2\" >1.3001</td>\n",
       "      <td id=\"T_e4e56_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_e4e56_row8_col4\" class=\"data row8 col4\" >0.5110</td>\n",
       "      <td id=\"T_e4e56_row8_col5\" class=\"data row8 col5\" >0.4779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_e4e56_row9_col0\" class=\"data row9 col0\" >0.8858</td>\n",
       "      <td id=\"T_e4e56_row9_col1\" class=\"data row9 col1\" >1.4707</td>\n",
       "      <td id=\"T_e4e56_row9_col2\" class=\"data row9 col2\" >1.2127</td>\n",
       "      <td id=\"T_e4e56_row9_col3\" class=\"data row9 col3\" >0.4906</td>\n",
       "      <td id=\"T_e4e56_row9_col4\" class=\"data row9 col4\" >0.4749</td>\n",
       "      <td id=\"T_e4e56_row9_col5\" class=\"data row9 col5\" >0.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_e4e56_row10_col0\" class=\"data row10 col0\" >0.9104</td>\n",
       "      <td id=\"T_e4e56_row10_col1\" class=\"data row10 col1\" >1.5445</td>\n",
       "      <td id=\"T_e4e56_row10_col2\" class=\"data row10 col2\" >1.2423</td>\n",
       "      <td id=\"T_e4e56_row10_col3\" class=\"data row10 col3\" >0.4716</td>\n",
       "      <td id=\"T_e4e56_row10_col4\" class=\"data row10 col4\" >0.4865</td>\n",
       "      <td id=\"T_e4e56_row10_col5\" class=\"data row10 col5\" >0.4527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e4e56_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_e4e56_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_e4e56_row11_col1\" class=\"data row11 col1\" >0.0860</td>\n",
       "      <td id=\"T_e4e56_row11_col2\" class=\"data row11 col2\" >0.0343</td>\n",
       "      <td id=\"T_e4e56_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_e4e56_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_e4e56_row11_col5\" class=\"data row11 col5\" >0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x157384970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_d1182_row10_col0, #T_d1182_row10_col1, #T_d1182_row10_col2, #T_d1182_row10_col3, #T_d1182_row10_col4, #T_d1182_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_d1182\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_d1182_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_d1182_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_d1182_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_d1182_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_d1182_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_d1182_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_d1182_row0_col0\" class=\"data row0 col0\" >0.8956</td>\n",
       "      <td id=\"T_d1182_row0_col1\" class=\"data row0 col1\" >1.4795</td>\n",
       "      <td id=\"T_d1182_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_d1182_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_d1182_row0_col4\" class=\"data row0 col4\" >0.4883</td>\n",
       "      <td id=\"T_d1182_row0_col5\" class=\"data row0 col5\" >0.4490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_d1182_row1_col0\" class=\"data row1 col0\" >0.9421</td>\n",
       "      <td id=\"T_d1182_row1_col1\" class=\"data row1 col1\" >1.6872</td>\n",
       "      <td id=\"T_d1182_row1_col2\" class=\"data row1 col2\" >1.2989</td>\n",
       "      <td id=\"T_d1182_row1_col3\" class=\"data row1 col3\" >0.4672</td>\n",
       "      <td id=\"T_d1182_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_d1182_row1_col5\" class=\"data row1 col5\" >0.4509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_d1182_row2_col0\" class=\"data row2 col0\" >0.9267</td>\n",
       "      <td id=\"T_d1182_row2_col1\" class=\"data row2 col1\" >1.5773</td>\n",
       "      <td id=\"T_d1182_row2_col2\" class=\"data row2 col2\" >1.2559</td>\n",
       "      <td id=\"T_d1182_row2_col3\" class=\"data row2 col3\" >0.4531</td>\n",
       "      <td id=\"T_d1182_row2_col4\" class=\"data row2 col4\" >0.4916</td>\n",
       "      <td id=\"T_d1182_row2_col5\" class=\"data row2 col5\" >0.4813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_d1182_row3_col0\" class=\"data row3 col0\" >0.8826</td>\n",
       "      <td id=\"T_d1182_row3_col1\" class=\"data row3 col1\" >1.4339</td>\n",
       "      <td id=\"T_d1182_row3_col2\" class=\"data row3 col2\" >1.1974</td>\n",
       "      <td id=\"T_d1182_row3_col3\" class=\"data row3 col3\" >0.4855</td>\n",
       "      <td id=\"T_d1182_row3_col4\" class=\"data row3 col4\" >0.4822</td>\n",
       "      <td id=\"T_d1182_row3_col5\" class=\"data row3 col5\" >0.4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_d1182_row4_col0\" class=\"data row4 col0\" >0.8739</td>\n",
       "      <td id=\"T_d1182_row4_col1\" class=\"data row4 col1\" >1.4666</td>\n",
       "      <td id=\"T_d1182_row4_col2\" class=\"data row4 col2\" >1.2110</td>\n",
       "      <td id=\"T_d1182_row4_col3\" class=\"data row4 col3\" >0.5154</td>\n",
       "      <td id=\"T_d1182_row4_col4\" class=\"data row4 col4\" >0.4619</td>\n",
       "      <td id=\"T_d1182_row4_col5\" class=\"data row4 col5\" >0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_d1182_row5_col0\" class=\"data row5 col0\" >0.9147</td>\n",
       "      <td id=\"T_d1182_row5_col1\" class=\"data row5 col1\" >1.5874</td>\n",
       "      <td id=\"T_d1182_row5_col2\" class=\"data row5 col2\" >1.2599</td>\n",
       "      <td id=\"T_d1182_row5_col3\" class=\"data row5 col3\" >0.4883</td>\n",
       "      <td id=\"T_d1182_row5_col4\" class=\"data row5 col4\" >0.4873</td>\n",
       "      <td id=\"T_d1182_row5_col5\" class=\"data row5 col5\" >0.4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_d1182_row6_col0\" class=\"data row6 col0\" >0.8939</td>\n",
       "      <td id=\"T_d1182_row6_col1\" class=\"data row6 col1\" >1.5073</td>\n",
       "      <td id=\"T_d1182_row6_col2\" class=\"data row6 col2\" >1.2277</td>\n",
       "      <td id=\"T_d1182_row6_col3\" class=\"data row6 col3\" >0.4792</td>\n",
       "      <td id=\"T_d1182_row6_col4\" class=\"data row6 col4\" >0.4880</td>\n",
       "      <td id=\"T_d1182_row6_col5\" class=\"data row6 col5\" >0.4354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_d1182_row7_col0\" class=\"data row7 col0\" >0.9257</td>\n",
       "      <td id=\"T_d1182_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_d1182_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_d1182_row7_col3\" class=\"data row7 col3\" >0.4362</td>\n",
       "      <td id=\"T_d1182_row7_col4\" class=\"data row7 col4\" >0.4990</td>\n",
       "      <td id=\"T_d1182_row7_col5\" class=\"data row7 col5\" >0.4820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_d1182_row8_col0\" class=\"data row8 col0\" >0.9600</td>\n",
       "      <td id=\"T_d1182_row8_col1\" class=\"data row8 col1\" >1.6901</td>\n",
       "      <td id=\"T_d1182_row8_col2\" class=\"data row8 col2\" >1.3000</td>\n",
       "      <td id=\"T_d1182_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_d1182_row8_col4\" class=\"data row8 col4\" >0.5109</td>\n",
       "      <td id=\"T_d1182_row8_col5\" class=\"data row8 col5\" >0.4773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_d1182_row9_col0\" class=\"data row9 col0\" >0.8855</td>\n",
       "      <td id=\"T_d1182_row9_col1\" class=\"data row9 col1\" >1.4703</td>\n",
       "      <td id=\"T_d1182_row9_col2\" class=\"data row9 col2\" >1.2126</td>\n",
       "      <td id=\"T_d1182_row9_col3\" class=\"data row9 col3\" >0.4907</td>\n",
       "      <td id=\"T_d1182_row9_col4\" class=\"data row9 col4\" >0.4747</td>\n",
       "      <td id=\"T_d1182_row9_col5\" class=\"data row9 col5\" >0.4297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_d1182_row10_col0\" class=\"data row10 col0\" >0.9101</td>\n",
       "      <td id=\"T_d1182_row10_col1\" class=\"data row10 col1\" >1.5443</td>\n",
       "      <td id=\"T_d1182_row10_col2\" class=\"data row10 col2\" >1.2422</td>\n",
       "      <td id=\"T_d1182_row10_col3\" class=\"data row10 col3\" >0.4716</td>\n",
       "      <td id=\"T_d1182_row10_col4\" class=\"data row10 col4\" >0.4864</td>\n",
       "      <td id=\"T_d1182_row10_col5\" class=\"data row10 col5\" >0.4521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_d1182_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_d1182_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_d1182_row11_col1\" class=\"data row11 col1\" >0.0860</td>\n",
       "      <td id=\"T_d1182_row11_col2\" class=\"data row11 col2\" >0.0343</td>\n",
       "      <td id=\"T_d1182_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_d1182_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_d1182_row11_col5\" class=\"data row11 col5\" >0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x157399c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_6600d_row10_col0, #T_6600d_row10_col1, #T_6600d_row10_col2, #T_6600d_row10_col3, #T_6600d_row10_col4, #T_6600d_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_6600d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_6600d_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_6600d_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_6600d_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_6600d_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_6600d_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_6600d_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_6600d_row0_col0\" class=\"data row0 col0\" >0.8958</td>\n",
       "      <td id=\"T_6600d_row0_col1\" class=\"data row0 col1\" >1.4796</td>\n",
       "      <td id=\"T_6600d_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_6600d_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_6600d_row0_col4\" class=\"data row0 col4\" >0.4884</td>\n",
       "      <td id=\"T_6600d_row0_col5\" class=\"data row0 col5\" >0.4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_6600d_row1_col0\" class=\"data row1 col0\" >0.9425</td>\n",
       "      <td id=\"T_6600d_row1_col1\" class=\"data row1 col1\" >1.6873</td>\n",
       "      <td id=\"T_6600d_row1_col2\" class=\"data row1 col2\" >1.2989</td>\n",
       "      <td id=\"T_6600d_row1_col3\" class=\"data row1 col3\" >0.4672</td>\n",
       "      <td id=\"T_6600d_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_6600d_row1_col5\" class=\"data row1 col5\" >0.4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_6600d_row2_col0\" class=\"data row2 col0\" >0.9270</td>\n",
       "      <td id=\"T_6600d_row2_col1\" class=\"data row2 col1\" >1.5778</td>\n",
       "      <td id=\"T_6600d_row2_col2\" class=\"data row2 col2\" >1.2561</td>\n",
       "      <td id=\"T_6600d_row2_col3\" class=\"data row2 col3\" >0.4529</td>\n",
       "      <td id=\"T_6600d_row2_col4\" class=\"data row2 col4\" >0.4917</td>\n",
       "      <td id=\"T_6600d_row2_col5\" class=\"data row2 col5\" >0.4819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_6600d_row3_col0\" class=\"data row3 col0\" >0.8829</td>\n",
       "      <td id=\"T_6600d_row3_col1\" class=\"data row3 col1\" >1.4339</td>\n",
       "      <td id=\"T_6600d_row3_col2\" class=\"data row3 col2\" >1.1975</td>\n",
       "      <td id=\"T_6600d_row3_col3\" class=\"data row3 col3\" >0.4855</td>\n",
       "      <td id=\"T_6600d_row3_col4\" class=\"data row3 col4\" >0.4823</td>\n",
       "      <td id=\"T_6600d_row3_col5\" class=\"data row3 col5\" >0.4304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_6600d_row4_col0\" class=\"data row4 col0\" >0.8742</td>\n",
       "      <td id=\"T_6600d_row4_col1\" class=\"data row4 col1\" >1.4666</td>\n",
       "      <td id=\"T_6600d_row4_col2\" class=\"data row4 col2\" >1.2110</td>\n",
       "      <td id=\"T_6600d_row4_col3\" class=\"data row4 col3\" >0.5154</td>\n",
       "      <td id=\"T_6600d_row4_col4\" class=\"data row4 col4\" >0.4621</td>\n",
       "      <td id=\"T_6600d_row4_col5\" class=\"data row4 col5\" >0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_6600d_row5_col0\" class=\"data row5 col0\" >0.9150</td>\n",
       "      <td id=\"T_6600d_row5_col1\" class=\"data row5 col1\" >1.5874</td>\n",
       "      <td id=\"T_6600d_row5_col2\" class=\"data row5 col2\" >1.2599</td>\n",
       "      <td id=\"T_6600d_row5_col3\" class=\"data row5 col3\" >0.4883</td>\n",
       "      <td id=\"T_6600d_row5_col4\" class=\"data row5 col4\" >0.4874</td>\n",
       "      <td id=\"T_6600d_row5_col5\" class=\"data row5 col5\" >0.4560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_6600d_row6_col0\" class=\"data row6 col0\" >0.8941</td>\n",
       "      <td id=\"T_6600d_row6_col1\" class=\"data row6 col1\" >1.5075</td>\n",
       "      <td id=\"T_6600d_row6_col2\" class=\"data row6 col2\" >1.2278</td>\n",
       "      <td id=\"T_6600d_row6_col3\" class=\"data row6 col3\" >0.4792</td>\n",
       "      <td id=\"T_6600d_row6_col4\" class=\"data row6 col4\" >0.4882</td>\n",
       "      <td id=\"T_6600d_row6_col5\" class=\"data row6 col5\" >0.4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_6600d_row7_col0\" class=\"data row7 col0\" >0.9260</td>\n",
       "      <td id=\"T_6600d_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_6600d_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_6600d_row7_col3\" class=\"data row7 col3\" >0.4361</td>\n",
       "      <td id=\"T_6600d_row7_col4\" class=\"data row7 col4\" >0.4991</td>\n",
       "      <td id=\"T_6600d_row7_col5\" class=\"data row7 col5\" >0.4826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_6600d_row8_col0\" class=\"data row8 col0\" >0.9603</td>\n",
       "      <td id=\"T_6600d_row8_col1\" class=\"data row8 col1\" >1.6902</td>\n",
       "      <td id=\"T_6600d_row8_col2\" class=\"data row8 col2\" >1.3001</td>\n",
       "      <td id=\"T_6600d_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_6600d_row8_col4\" class=\"data row8 col4\" >0.5110</td>\n",
       "      <td id=\"T_6600d_row8_col5\" class=\"data row8 col5\" >0.4779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_6600d_row9_col0\" class=\"data row9 col0\" >0.8858</td>\n",
       "      <td id=\"T_6600d_row9_col1\" class=\"data row9 col1\" >1.4707</td>\n",
       "      <td id=\"T_6600d_row9_col2\" class=\"data row9 col2\" >1.2127</td>\n",
       "      <td id=\"T_6600d_row9_col3\" class=\"data row9 col3\" >0.4906</td>\n",
       "      <td id=\"T_6600d_row9_col4\" class=\"data row9 col4\" >0.4749</td>\n",
       "      <td id=\"T_6600d_row9_col5\" class=\"data row9 col5\" >0.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_6600d_row10_col0\" class=\"data row10 col0\" >0.9104</td>\n",
       "      <td id=\"T_6600d_row10_col1\" class=\"data row10 col1\" >1.5445</td>\n",
       "      <td id=\"T_6600d_row10_col2\" class=\"data row10 col2\" >1.2423</td>\n",
       "      <td id=\"T_6600d_row10_col3\" class=\"data row10 col3\" >0.4716</td>\n",
       "      <td id=\"T_6600d_row10_col4\" class=\"data row10 col4\" >0.4865</td>\n",
       "      <td id=\"T_6600d_row10_col5\" class=\"data row10 col5\" >0.4527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_6600d_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_6600d_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_6600d_row11_col1\" class=\"data row11 col1\" >0.0860</td>\n",
       "      <td id=\"T_6600d_row11_col2\" class=\"data row11 col2\" >0.0343</td>\n",
       "      <td id=\"T_6600d_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_6600d_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_6600d_row11_col5\" class=\"data row11 col5\" >0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15738bf70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n",
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c31d3_row10_col0, #T_c31d3_row10_col1, #T_c31d3_row10_col2, #T_c31d3_row10_col3, #T_c31d3_row10_col4, #T_c31d3_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c31d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c31d3_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_c31d3_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_c31d3_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_c31d3_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_c31d3_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_c31d3_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c31d3_row0_col0\" class=\"data row0 col0\" >0.8958</td>\n",
       "      <td id=\"T_c31d3_row0_col1\" class=\"data row0 col1\" >1.4796</td>\n",
       "      <td id=\"T_c31d3_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_c31d3_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_c31d3_row0_col4\" class=\"data row0 col4\" >0.4884</td>\n",
       "      <td id=\"T_c31d3_row0_col5\" class=\"data row0 col5\" >0.4495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c31d3_row1_col0\" class=\"data row1 col0\" >0.9421</td>\n",
       "      <td id=\"T_c31d3_row1_col1\" class=\"data row1 col1\" >1.6862</td>\n",
       "      <td id=\"T_c31d3_row1_col2\" class=\"data row1 col2\" >1.2986</td>\n",
       "      <td id=\"T_c31d3_row1_col3\" class=\"data row1 col3\" >0.4675</td>\n",
       "      <td id=\"T_c31d3_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_c31d3_row1_col5\" class=\"data row1 col5\" >0.4512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c31d3_row2_col0\" class=\"data row2 col0\" >0.9265</td>\n",
       "      <td id=\"T_c31d3_row2_col1\" class=\"data row2 col1\" >1.5753</td>\n",
       "      <td id=\"T_c31d3_row2_col2\" class=\"data row2 col2\" >1.2551</td>\n",
       "      <td id=\"T_c31d3_row2_col3\" class=\"data row2 col3\" >0.4538</td>\n",
       "      <td id=\"T_c31d3_row2_col4\" class=\"data row2 col4\" >0.4915</td>\n",
       "      <td id=\"T_c31d3_row2_col5\" class=\"data row2 col5\" >0.4815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c31d3_row3_col0\" class=\"data row3 col0\" >0.8828</td>\n",
       "      <td id=\"T_c31d3_row3_col1\" class=\"data row3 col1\" >1.4336</td>\n",
       "      <td id=\"T_c31d3_row3_col2\" class=\"data row3 col2\" >1.1973</td>\n",
       "      <td id=\"T_c31d3_row3_col3\" class=\"data row3 col3\" >0.4856</td>\n",
       "      <td id=\"T_c31d3_row3_col4\" class=\"data row3 col4\" >0.4823</td>\n",
       "      <td id=\"T_c31d3_row3_col5\" class=\"data row3 col5\" >0.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c31d3_row4_col0\" class=\"data row4 col0\" >0.8741</td>\n",
       "      <td id=\"T_c31d3_row4_col1\" class=\"data row4 col1\" >1.4662</td>\n",
       "      <td id=\"T_c31d3_row4_col2\" class=\"data row4 col2\" >1.2109</td>\n",
       "      <td id=\"T_c31d3_row4_col3\" class=\"data row4 col3\" >0.5155</td>\n",
       "      <td id=\"T_c31d3_row4_col4\" class=\"data row4 col4\" >0.4619</td>\n",
       "      <td id=\"T_c31d3_row4_col5\" class=\"data row4 col5\" >0.4310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_c31d3_row5_col0\" class=\"data row5 col0\" >0.9148</td>\n",
       "      <td id=\"T_c31d3_row5_col1\" class=\"data row5 col1\" >1.5868</td>\n",
       "      <td id=\"T_c31d3_row5_col2\" class=\"data row5 col2\" >1.2597</td>\n",
       "      <td id=\"T_c31d3_row5_col3\" class=\"data row5 col3\" >0.4884</td>\n",
       "      <td id=\"T_c31d3_row5_col4\" class=\"data row5 col4\" >0.4874</td>\n",
       "      <td id=\"T_c31d3_row5_col5\" class=\"data row5 col5\" >0.4558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_c31d3_row6_col0\" class=\"data row6 col0\" >0.8942</td>\n",
       "      <td id=\"T_c31d3_row6_col1\" class=\"data row6 col1\" >1.5077</td>\n",
       "      <td id=\"T_c31d3_row6_col2\" class=\"data row6 col2\" >1.2279</td>\n",
       "      <td id=\"T_c31d3_row6_col3\" class=\"data row6 col3\" >0.4791</td>\n",
       "      <td id=\"T_c31d3_row6_col4\" class=\"data row6 col4\" >0.4882</td>\n",
       "      <td id=\"T_c31d3_row6_col5\" class=\"data row6 col5\" >0.4359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_c31d3_row7_col0\" class=\"data row7 col0\" >0.9259</td>\n",
       "      <td id=\"T_c31d3_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_c31d3_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_c31d3_row7_col3\" class=\"data row7 col3\" >0.4362</td>\n",
       "      <td id=\"T_c31d3_row7_col4\" class=\"data row7 col4\" >0.4991</td>\n",
       "      <td id=\"T_c31d3_row7_col5\" class=\"data row7 col5\" >0.4825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_c31d3_row8_col0\" class=\"data row8 col0\" >0.9601</td>\n",
       "      <td id=\"T_c31d3_row8_col1\" class=\"data row8 col1\" >1.6900</td>\n",
       "      <td id=\"T_c31d3_row8_col2\" class=\"data row8 col2\" >1.3000</td>\n",
       "      <td id=\"T_c31d3_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_c31d3_row8_col4\" class=\"data row8 col4\" >0.5110</td>\n",
       "      <td id=\"T_c31d3_row8_col5\" class=\"data row8 col5\" >0.4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_c31d3_row9_col0\" class=\"data row9 col0\" >0.8858</td>\n",
       "      <td id=\"T_c31d3_row9_col1\" class=\"data row9 col1\" >1.4707</td>\n",
       "      <td id=\"T_c31d3_row9_col2\" class=\"data row9 col2\" >1.2127</td>\n",
       "      <td id=\"T_c31d3_row9_col3\" class=\"data row9 col3\" >0.4906</td>\n",
       "      <td id=\"T_c31d3_row9_col4\" class=\"data row9 col4\" >0.4749</td>\n",
       "      <td id=\"T_c31d3_row9_col5\" class=\"data row9 col5\" >0.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_c31d3_row10_col0\" class=\"data row10 col0\" >0.9102</td>\n",
       "      <td id=\"T_c31d3_row10_col1\" class=\"data row10 col1\" >1.5440</td>\n",
       "      <td id=\"T_c31d3_row10_col2\" class=\"data row10 col2\" >1.2421</td>\n",
       "      <td id=\"T_c31d3_row10_col3\" class=\"data row10 col3\" >0.4717</td>\n",
       "      <td id=\"T_c31d3_row10_col4\" class=\"data row10 col4\" >0.4865</td>\n",
       "      <td id=\"T_c31d3_row10_col5\" class=\"data row10 col5\" >0.4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c31d3_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_c31d3_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_c31d3_row11_col1\" class=\"data row11 col1\" >0.0857</td>\n",
       "      <td id=\"T_c31d3_row11_col2\" class=\"data row11 col2\" >0.0342</td>\n",
       "      <td id=\"T_c31d3_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_c31d3_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_c31d3_row11_col5\" class=\"data row11 col5\" >0.0203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x15c5e13a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b17da_row10_col0, #T_b17da_row10_col1, #T_b17da_row10_col2, #T_b17da_row10_col3, #T_b17da_row10_col4, #T_b17da_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b17da\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b17da_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_b17da_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_b17da_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_b17da_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_b17da_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_b17da_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b17da_row0_col0\" class=\"data row0 col0\" >0.8957</td>\n",
       "      <td id=\"T_b17da_row0_col1\" class=\"data row0 col1\" >1.4796</td>\n",
       "      <td id=\"T_b17da_row0_col2\" class=\"data row0 col2\" >1.2164</td>\n",
       "      <td id=\"T_b17da_row0_col3\" class=\"data row0 col3\" >0.4717</td>\n",
       "      <td id=\"T_b17da_row0_col4\" class=\"data row0 col4\" >0.4884</td>\n",
       "      <td id=\"T_b17da_row0_col5\" class=\"data row0 col5\" >0.4493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b17da_row1_col0\" class=\"data row1 col0\" >0.9422</td>\n",
       "      <td id=\"T_b17da_row1_col1\" class=\"data row1 col1\" >1.6870</td>\n",
       "      <td id=\"T_b17da_row1_col2\" class=\"data row1 col2\" >1.2988</td>\n",
       "      <td id=\"T_b17da_row1_col3\" class=\"data row1 col3\" >0.4672</td>\n",
       "      <td id=\"T_b17da_row1_col4\" class=\"data row1 col4\" >0.4799</td>\n",
       "      <td id=\"T_b17da_row1_col5\" class=\"data row1 col5\" >0.4513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b17da_row2_col0\" class=\"data row2 col0\" >0.9268</td>\n",
       "      <td id=\"T_b17da_row2_col1\" class=\"data row2 col1\" >1.5771</td>\n",
       "      <td id=\"T_b17da_row2_col2\" class=\"data row2 col2\" >1.2558</td>\n",
       "      <td id=\"T_b17da_row2_col3\" class=\"data row2 col3\" >0.4532</td>\n",
       "      <td id=\"T_b17da_row2_col4\" class=\"data row2 col4\" >0.4916</td>\n",
       "      <td id=\"T_b17da_row2_col5\" class=\"data row2 col5\" >0.4816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b17da_row3_col0\" class=\"data row3 col0\" >0.8828</td>\n",
       "      <td id=\"T_b17da_row3_col1\" class=\"data row3 col1\" >1.4338</td>\n",
       "      <td id=\"T_b17da_row3_col2\" class=\"data row3 col2\" >1.1974</td>\n",
       "      <td id=\"T_b17da_row3_col3\" class=\"data row3 col3\" >0.4855</td>\n",
       "      <td id=\"T_b17da_row3_col4\" class=\"data row3 col4\" >0.4822</td>\n",
       "      <td id=\"T_b17da_row3_col5\" class=\"data row3 col5\" >0.4301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b17da_row4_col0\" class=\"data row4 col0\" >0.8740</td>\n",
       "      <td id=\"T_b17da_row4_col1\" class=\"data row4 col1\" >1.4665</td>\n",
       "      <td id=\"T_b17da_row4_col2\" class=\"data row4 col2\" >1.2110</td>\n",
       "      <td id=\"T_b17da_row4_col3\" class=\"data row4 col3\" >0.5154</td>\n",
       "      <td id=\"T_b17da_row4_col4\" class=\"data row4 col4\" >0.4620</td>\n",
       "      <td id=\"T_b17da_row4_col5\" class=\"data row4 col5\" >0.4308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b17da_row5_col0\" class=\"data row5 col0\" >0.9148</td>\n",
       "      <td id=\"T_b17da_row5_col1\" class=\"data row5 col1\" >1.5872</td>\n",
       "      <td id=\"T_b17da_row5_col2\" class=\"data row5 col2\" >1.2599</td>\n",
       "      <td id=\"T_b17da_row5_col3\" class=\"data row5 col3\" >0.4883</td>\n",
       "      <td id=\"T_b17da_row5_col4\" class=\"data row5 col4\" >0.4874</td>\n",
       "      <td id=\"T_b17da_row5_col5\" class=\"data row5 col5\" >0.4557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b17da_row6_col0\" class=\"data row6 col0\" >0.8941</td>\n",
       "      <td id=\"T_b17da_row6_col1\" class=\"data row6 col1\" >1.5075</td>\n",
       "      <td id=\"T_b17da_row6_col2\" class=\"data row6 col2\" >1.2278</td>\n",
       "      <td id=\"T_b17da_row6_col3\" class=\"data row6 col3\" >0.4792</td>\n",
       "      <td id=\"T_b17da_row6_col4\" class=\"data row6 col4\" >0.4881</td>\n",
       "      <td id=\"T_b17da_row6_col5\" class=\"data row6 col5\" >0.4357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b17da_row7_col0\" class=\"data row7 col0\" >0.9258</td>\n",
       "      <td id=\"T_b17da_row7_col1\" class=\"data row7 col1\" >1.5440</td>\n",
       "      <td id=\"T_b17da_row7_col2\" class=\"data row7 col2\" >1.2426</td>\n",
       "      <td id=\"T_b17da_row7_col3\" class=\"data row7 col3\" >0.4362</td>\n",
       "      <td id=\"T_b17da_row7_col4\" class=\"data row7 col4\" >0.4990</td>\n",
       "      <td id=\"T_b17da_row7_col5\" class=\"data row7 col5\" >0.4824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b17da_row8_col0\" class=\"data row8 col0\" >0.9601</td>\n",
       "      <td id=\"T_b17da_row8_col1\" class=\"data row8 col1\" >1.6901</td>\n",
       "      <td id=\"T_b17da_row8_col2\" class=\"data row8 col2\" >1.3000</td>\n",
       "      <td id=\"T_b17da_row8_col3\" class=\"data row8 col3\" >0.4288</td>\n",
       "      <td id=\"T_b17da_row8_col4\" class=\"data row8 col4\" >0.5109</td>\n",
       "      <td id=\"T_b17da_row8_col5\" class=\"data row8 col5\" >0.4777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b17da_row9_col0\" class=\"data row9 col0\" >0.8857</td>\n",
       "      <td id=\"T_b17da_row9_col1\" class=\"data row9 col1\" >1.4706</td>\n",
       "      <td id=\"T_b17da_row9_col2\" class=\"data row9 col2\" >1.2127</td>\n",
       "      <td id=\"T_b17da_row9_col3\" class=\"data row9 col3\" >0.4907</td>\n",
       "      <td id=\"T_b17da_row9_col4\" class=\"data row9 col4\" >0.4748</td>\n",
       "      <td id=\"T_b17da_row9_col5\" class=\"data row9 col5\" >0.4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_b17da_row10_col0\" class=\"data row10 col0\" >0.9102</td>\n",
       "      <td id=\"T_b17da_row10_col1\" class=\"data row10 col1\" >1.5443</td>\n",
       "      <td id=\"T_b17da_row10_col2\" class=\"data row10 col2\" >1.2422</td>\n",
       "      <td id=\"T_b17da_row10_col3\" class=\"data row10 col3\" >0.4716</td>\n",
       "      <td id=\"T_b17da_row10_col4\" class=\"data row10 col4\" >0.4864</td>\n",
       "      <td id=\"T_b17da_row10_col5\" class=\"data row10 col5\" >0.4524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b17da_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_b17da_row11_col0\" class=\"data row11 col0\" >0.0268</td>\n",
       "      <td id=\"T_b17da_row11_col1\" class=\"data row11 col1\" >0.0859</td>\n",
       "      <td id=\"T_b17da_row11_col2\" class=\"data row11 col2\" >0.0343</td>\n",
       "      <td id=\"T_b17da_row11_col3\" class=\"data row11 col3\" >0.0250</td>\n",
       "      <td id=\"T_b17da_row11_col4\" class=\"data row11 col4\" >0.0126</td>\n",
       "      <td id=\"T_b17da_row11_col5\" class=\"data row11 col5\" >0.0204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1573b7e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이창훈\n",
    "male_best_model_5 = compare_models(sort='RMSE', n_select = 5)\n",
    "male_tuned_top5 = [tune_model(i, optimize = 'RMSE', n_iter=10) for i in male_best_model_5]\n",
    "model_male = blend_models(estimator_list=male_tuned_top5, optimize = 'RMSE')\n",
    "\n",
    "# 이이슬\n",
    "# male_best_model_5 = compare_models(sort='RMSE', n_select = 5)\n",
    "# model_male = ensemble_model(male_best_model_5[0], method='Bagging', choose_better = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a7acd9",
   "metadata": {},
   "source": [
    "# 2016년 예측(남자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a795a025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>773278</td>\n",
       "      <td>12.405500</td>\n",
       "      <td>83.354839</td>\n",
       "      <td>3.845070</td>\n",
       "      <td>1027.575000</td>\n",
       "      <td>33.314706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-0.271831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6015357</td>\n",
       "      <td>7.388123</td>\n",
       "      <td>65.448276</td>\n",
       "      <td>5.413208</td>\n",
       "      <td>1025.875000</td>\n",
       "      <td>28.227586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>3.124528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1664755</td>\n",
       "      <td>9.147472</td>\n",
       "      <td>74.583333</td>\n",
       "      <td>3.112821</td>\n",
       "      <td>1023.921429</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.3</td>\n",
       "      <td>4.946154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1355727</td>\n",
       "      <td>12.284700</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>3.338182</td>\n",
       "      <td>1026.137500</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.5</td>\n",
       "      <td>2.923636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>725606</td>\n",
       "      <td>7.629485</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>1022.900000</td>\n",
       "      <td>23.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.3</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31581</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>951889</td>\n",
       "      <td>16.677050</td>\n",
       "      <td>65.555094</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>1030.607692</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>33.635000</td>\n",
       "      <td>42.6</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>927505</td>\n",
       "      <td>15.011563</td>\n",
       "      <td>72.161486</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>1030.586667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>52.149758</td>\n",
       "      <td>41.4</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>322545</td>\n",
       "      <td>11.278426</td>\n",
       "      <td>60.569257</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1029.900000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.460474</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1064765</td>\n",
       "      <td>13.768860</td>\n",
       "      <td>75.118243</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>1030.100000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>71.473958</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>803240</td>\n",
       "      <td>12.472486</td>\n",
       "      <td>72.665541</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1031.400000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>60.829167</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-6.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31586 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  yyyy  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  \\\n",
       "0       강원  2011  12   1        3     773278      12.405500  83.354839   \n",
       "1       경기  2011  12   1        3    6015357       7.388123  65.448276   \n",
       "2       경남  2011  12   1        3    1664755       9.147472  74.583333   \n",
       "3       경북  2011  12   1        3    1355727      12.284700  81.000000   \n",
       "4       광주  2011  12   1        3     725606       7.629485  89.000000   \n",
       "...    ...   ...  ..  ..      ...        ...            ...        ...   \n",
       "31581   전남  2016  12  31        5     951889      16.677050  65.555094   \n",
       "31582   전북  2016  12  31        5     927505      15.011563  72.161486   \n",
       "31583   제주  2016  12  31        5     322545      11.278426  60.569257   \n",
       "31584   충남  2016  12  31        5    1064765      13.768860  75.118243   \n",
       "31585   충북  2016  12  31        5     803240      12.472486  72.665541   \n",
       "\n",
       "       diff_temp       avg_ps   diff_hum    pm10_7b  avg_age  min_temp  \\\n",
       "0       3.845070  1027.575000  33.314706        NaN     39.3 -0.271831   \n",
       "1       5.413208  1025.875000  28.227586        NaN     36.0  3.124528   \n",
       "2       3.112821  1023.921429  19.566667        NaN     37.3  4.946154   \n",
       "3       3.338182  1026.137500  28.800000        NaN     39.5  2.923636   \n",
       "4       3.840000  1022.900000  23.066667        NaN     35.3  4.740000   \n",
       "...          ...          ...        ...        ...      ...       ...   \n",
       "31581  13.700000  1030.607692  49.000000  33.635000     42.6 -4.700000   \n",
       "31582  14.500000  1030.586667  42.000000  52.149758     41.4 -7.000000   \n",
       "31583   8.000000  1029.900000  31.000000  28.460474     39.2  2.500000   \n",
       "31584  11.700000  1030.100000  41.000000  71.473958     40.7 -4.000000   \n",
       "31585  12.000000  1031.400000  35.000000  60.829167     40.5 -6.800000   \n",
       "\n",
       "       frequency  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "31581        NaN  \n",
       "31582        NaN  \n",
       "31583        NaN  \n",
       "31584        NaN  \n",
       "31585        NaN  \n",
       "\n",
       "[31586 rows x 15 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_male = pd.read_csv('./hospital_male_0802_test3.csv', encoding='cp949') #이 csv 파일은 2016년 데이터까지 포함한 것\n",
    "# dataset3.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test_male = test_male[['area','yyyy','mm','dd','weekday','total_pop','elderly_ratio',\n",
    "                          'avg_hum','diff_temp','avg_ps','diff_hum','pm10_7b',\n",
    "                          'avg_age','min_temp','frequency']]\n",
    "#     ['area','yyyy','dd','mm','weekday','heat_wave','cold_wave','total_pop','elderly_ratio',\n",
    "#                           'pm10_7b','diff_hum','diff_temp','avg_ps',\n",
    "#                           'avg_age','min_max_ps', 'avg_hum','frequency']]\n",
    "test_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a517ae51",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>781185</td>\n",
       "      <td>14.022671</td>\n",
       "      <td>58.196911</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1030.230000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.954167</td>\n",
       "      <td>41.4</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6306634</td>\n",
       "      <td>8.966558</td>\n",
       "      <td>70.844595</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1031.633333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.487621</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1695187</td>\n",
       "      <td>10.962802</td>\n",
       "      <td>52.099421</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1031.175000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.128224</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1356568</td>\n",
       "      <td>14.384461</td>\n",
       "      <td>57.314554</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1030.309524</td>\n",
       "      <td>66.0</td>\n",
       "      <td>38.389385</td>\n",
       "      <td>41.5</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>729995</td>\n",
       "      <td>9.572120</td>\n",
       "      <td>62.837838</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1032.200000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>37.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>951889</td>\n",
       "      <td>16.677050</td>\n",
       "      <td>65.555094</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1030.607692</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.635000</td>\n",
       "      <td>42.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>927505</td>\n",
       "      <td>15.011563</td>\n",
       "      <td>72.161486</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1030.586667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.149758</td>\n",
       "      <td>41.4</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>322545</td>\n",
       "      <td>11.278426</td>\n",
       "      <td>60.569257</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1029.900000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.460474</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1064765</td>\n",
       "      <td>13.768860</td>\n",
       "      <td>75.118243</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1030.100000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.473958</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>803240</td>\n",
       "      <td>12.472486</td>\n",
       "      <td>72.665541</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1031.400000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.829167</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  \\\n",
       "0      강원  2016   1   1        4     781185      14.022671  58.196911   \n",
       "1      경기  2016   1   1        4    6306634       8.966558  70.844595   \n",
       "2      경남  2016   1   1        4    1695187      10.962802  52.099421   \n",
       "3      경북  2016   1   1        4    1356568      14.384461  57.314554   \n",
       "4      광주  2016   1   1        4     729995       9.572120  62.837838   \n",
       "...   ...   ...  ..  ..      ...        ...            ...        ...   \n",
       "6217   전남  2016  12  31        5     951889      16.677050  65.555094   \n",
       "6218   전북  2016  12  31        5     927505      15.011563  72.161486   \n",
       "6219   제주  2016  12  31        5     322545      11.278426  60.569257   \n",
       "6220   충남  2016  12  31        5    1064765      13.768860  75.118243   \n",
       "6221   충북  2016  12  31        5     803240      12.472486  72.665541   \n",
       "\n",
       "      diff_temp       avg_ps  diff_hum    pm10_7b  avg_age  min_temp  \\\n",
       "0          18.9  1030.230000      73.0  61.954167     41.4      -8.9   \n",
       "1          12.1  1031.633333      45.0  42.487621     38.0      -6.9   \n",
       "2          17.7  1031.175000      79.0  29.128224     39.3      -7.0   \n",
       "3          20.0  1030.309524      66.0  38.389385     41.5     -10.0   \n",
       "4          10.0  1032.200000      40.0  20.475000     37.4      -2.0   \n",
       "...         ...          ...       ...        ...      ...       ...   \n",
       "6217       13.7  1030.607692      49.0  33.635000     42.6      -4.7   \n",
       "6218       14.5  1030.586667      42.0  52.149758     41.4      -7.0   \n",
       "6219        8.0  1029.900000      31.0  28.460474     39.2       2.5   \n",
       "6220       11.7  1030.100000      41.0  71.473958     40.7      -4.0   \n",
       "6221       12.0  1031.400000      35.0  60.829167     40.5      -6.8   \n",
       "\n",
       "      frequency  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "6217        NaN  \n",
       "6218        NaN  \n",
       "6219        NaN  \n",
       "6220        NaN  \n",
       "6221        NaN  \n",
       "\n",
       "[6222 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_male2 = test_male[test_male['yyyy'].astype(str).str.contains('2016')].reset_index(drop=True)#2016년만 추출\n",
    "test_male2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd344fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_male3 = test_male2.drop(columns=['frequency','yyyy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fb6fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "male_final_model = finalize_model(model_male)\n",
    "prediction_male = predict_model(male_final_model, data = test_male3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4364b9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_male['Label'] = prediction_male['Label'].round(0)\n",
    "# prediction_male[['Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d73cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c6eafde",
   "metadata": {},
   "source": [
    "# 2012-2015년 데이터로 모델 만들기(여자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84eab207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>762617</td>\n",
       "      <td>18.053361</td>\n",
       "      <td>58.333333</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1023.886667</td>\n",
       "      <td>65.0</td>\n",
       "      <td>30.158333</td>\n",
       "      <td>42.4</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5928150</td>\n",
       "      <td>10.649039</td>\n",
       "      <td>50.733333</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1024.875000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.537404</td>\n",
       "      <td>37.7</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1644251</td>\n",
       "      <td>15.076105</td>\n",
       "      <td>44.916667</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1022.950000</td>\n",
       "      <td>47.0</td>\n",
       "      <td>26.719907</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1342455</td>\n",
       "      <td>19.248690</td>\n",
       "      <td>52.377778</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1023.268000</td>\n",
       "      <td>70.0</td>\n",
       "      <td>25.336806</td>\n",
       "      <td>43.2</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>738784</td>\n",
       "      <td>11.037868</td>\n",
       "      <td>75.833333</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1025.250000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>18.958333</td>\n",
       "      <td>37.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24832</th>\n",
       "      <td>전남</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>955115</td>\n",
       "      <td>24.847060</td>\n",
       "      <td>66.764033</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1031.053846</td>\n",
       "      <td>65.0</td>\n",
       "      <td>46.708333</td>\n",
       "      <td>45.9</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24833</th>\n",
       "      <td>전북</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>939456</td>\n",
       "      <td>21.104873</td>\n",
       "      <td>73.750000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1031.300000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.548882</td>\n",
       "      <td>44.2</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24834</th>\n",
       "      <td>제주</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>310967</td>\n",
       "      <td>16.470236</td>\n",
       "      <td>59.915541</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1030.792308</td>\n",
       "      <td>33.0</td>\n",
       "      <td>56.156250</td>\n",
       "      <td>41.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24835</th>\n",
       "      <td>충남</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1023210</td>\n",
       "      <td>19.459055</td>\n",
       "      <td>74.725225</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1031.513333</td>\n",
       "      <td>55.0</td>\n",
       "      <td>79.543252</td>\n",
       "      <td>43.1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24836</th>\n",
       "      <td>충북</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>785056</td>\n",
       "      <td>17.517604</td>\n",
       "      <td>70.658784</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1030.850000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>74.573958</td>\n",
       "      <td>42.7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24837 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  diff_temp  \\\n",
       "0       강원   1   1        6     762617      18.053361  58.333333       12.3   \n",
       "1       경기   1   1        6    5928150      10.649039  50.733333        7.9   \n",
       "2       경남   1   1        6    1644251      15.076105  44.916667        9.9   \n",
       "3       경북   1   1        6    1342455      19.248690  52.377778       12.0   \n",
       "4       광주   1   1        6     738784      11.037868  75.833333        3.9   \n",
       "...    ...  ..  ..      ...        ...            ...        ...        ...   \n",
       "24832   전남  12  31        3     955115      24.847060  66.764033       12.3   \n",
       "24833   전북  12  31        3     939456      21.104873  73.750000       10.0   \n",
       "24834   제주  12  31        3     310967      16.470236  59.915541        4.9   \n",
       "24835   충남  12  31        3    1023210      19.459055  74.725225        9.0   \n",
       "24836   충북  12  31        3     785056      17.517604  70.658784       10.1   \n",
       "\n",
       "            avg_ps  diff_hum    pm10_7b  avg_age  min_temp  frequency  \n",
       "0      1023.886667      65.0  30.158333     42.4      -7.3        3.0  \n",
       "1      1024.875000      27.0  28.537404     37.7      -6.9        5.0  \n",
       "2      1022.950000      47.0  26.719907     40.5      -2.9        1.0  \n",
       "3      1023.268000      70.0  25.336806     43.2      -5.9        1.0  \n",
       "4      1025.250000      15.0  18.958333     37.6      -0.9        2.0  \n",
       "...            ...       ...        ...      ...       ...        ...  \n",
       "24832  1031.053846      65.0  46.708333     45.9      -2.3        3.0  \n",
       "24833  1031.300000      50.0  72.548882     44.2      -3.0        0.0  \n",
       "24834  1030.792308      33.0  56.156250     41.5       5.4        0.0  \n",
       "24835  1031.513333      55.0  79.543252     43.1      -3.0        0.0  \n",
       "24836  1030.850000      55.0  74.573958     42.7      -4.0        0.0  \n",
       "\n",
       "[24837 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_female = pd.read_csv('./hospital_female_0802_test3.csv', encoding='cp949')\n",
    "dataset_female = dataset_female[dataset_female['yyyy'].astype(str).str.contains('2012|2013|2014|2015')].reset_index(drop=True)#2016년 전만 추출\n",
    "# dataset_female.drop(columns=['sex'], inplace=True)\n",
    "# dataset_female.to_csv('female_df.csv', encoding='cp949')\n",
    "female_df = dataset_female[['area','mm','dd','weekday','total_pop','elderly_ratio',\n",
    "                          'avg_hum','diff_temp','avg_ps','diff_hum','pm10_7b',\n",
    "                          'avg_age','min_temp','frequency']]\n",
    "#     ['area','mm','weekday','heat_wave','cold_wave','total_pop','elderly_ratio',\n",
    "#           'pm10_7b','diff_hum','diff_temp','avg_ps',\n",
    "#           'avg_age','min_max_ps','frequency']]\n",
    "# fixed_df = dataset2[['area', 'mm', 'frequency','total_pop', 'elderly_ratio','so2','pm10','rhm_min_avg_dif','min_max_Ta','avg_ps']]\n",
    "female_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888c8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3 = female_df.quantile(0.75) # df['국어'].quantile(0.75) 처럼 특정 열만 적용 가능\n",
    "# q1 = female_df.quantile(0.25)\n",
    "\n",
    "# iqr = q3 - q1\n",
    "\n",
    "# def is_freq_outlier(df):\n",
    "#     freq_score = df['frequency']\n",
    "#     if freq_score > 10:\n",
    "# #     if freq_score > q3['frequency'] + 1.5 * iqr['frequency'] or freq_score < q1['frequency'] - 1.5 * iqr['frequency']:\n",
    "#         return True\n",
    "#     else:\n",
    "#         return False\n",
    "\n",
    "# # apply 함수를 통하여 각 값의 이상치 여부를 찾고 새로운 열에 결과 저장\n",
    "# female_df['freq_outlier'] = female_df.apply(is_freq_outlier, axis = 1) # axis = 1 지정 필수\n",
    "# # female_df[female_df['freq_outlier']==True]\n",
    "# female_df = female_df.drop(female_df[female_df['freq_outlier']==True].index, axis=0)\n",
    "# female_df.drop(columns=['freq_outlier'], inplace=True)\n",
    "# female_df.reset_index(drop=True, inplace=True)\n",
    "# female_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7601f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for Modeling: (19870, 14)\n",
      "Unseen Data For Predictions: (4967, 14)\n"
     ]
    }
   ],
   "source": [
    "female_data = female_df.sample(frac=0.8, random_state=786) \n",
    "female_data_unseen = female_df.drop(female_data.index) \n",
    "\n",
    "female_data.reset_index(drop=True, inplace=True) \n",
    "female_data_unseen.reset_index(drop=True, inplace=True) \n",
    "\n",
    "print('Data for Modeling: ' + str(female_data.shape)) \n",
    "print('Unseen Data For Predictions: ' + str(female_data_unseen.shape)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b630ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>세종</td>\n",
       "      <td>10</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>58172</td>\n",
       "      <td>18.113525</td>\n",
       "      <td>79.712121</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1021.800000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>41.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대구</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1254686</td>\n",
       "      <td>13.887140</td>\n",
       "      <td>49.216216</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1010.350000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>43.726190</td>\n",
       "      <td>41.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>전북</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>939716</td>\n",
       "      <td>18.846226</td>\n",
       "      <td>60.965488</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1024.564286</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.974537</td>\n",
       "      <td>42.2</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>서울</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5101462</td>\n",
       "      <td>13.790870</td>\n",
       "      <td>48.851351</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1020.600000</td>\n",
       "      <td>65.0</td>\n",
       "      <td>45.331092</td>\n",
       "      <td>41.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>서울</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>5168051</td>\n",
       "      <td>11.833958</td>\n",
       "      <td>65.340909</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1006.200000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>33.968521</td>\n",
       "      <td>39.9</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>광주</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>744388</td>\n",
       "      <td>12.344906</td>\n",
       "      <td>80.151515</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1006.350000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>11.650000</td>\n",
       "      <td>38.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>대구</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>1255618</td>\n",
       "      <td>13.792650</td>\n",
       "      <td>43.166667</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1020.000000</td>\n",
       "      <td>64.0</td>\n",
       "      <td>42.598685</td>\n",
       "      <td>41.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>대전</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>759431</td>\n",
       "      <td>10.719473</td>\n",
       "      <td>54.136364</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1012.300000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>58.950000</td>\n",
       "      <td>38.1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>경북</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1345200</td>\n",
       "      <td>21.171796</td>\n",
       "      <td>77.572523</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1030.790476</td>\n",
       "      <td>45.0</td>\n",
       "      <td>58.179159</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19869</th>\n",
       "      <td>제주</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>291639</td>\n",
       "      <td>15.969401</td>\n",
       "      <td>69.151515</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1019.050000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>56.145833</td>\n",
       "      <td>40.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19870 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  diff_temp  \\\n",
       "0       세종  10  29        1      58172      18.113525  79.712121       15.5   \n",
       "1       대구   5   8        3    1254686      13.887140  49.216216       10.3   \n",
       "2       전북   1  22        6     939716      18.846226  60.965488        8.9   \n",
       "3       서울  10  14        2    5101462      13.790870  48.851351       13.0   \n",
       "4       서울   7   9        0    5168051      11.833958  65.340909       10.0   \n",
       "...    ...  ..  ..      ...        ...            ...        ...        ...   \n",
       "19865   광주   7  25        4     744388      12.344906  80.151515        6.0   \n",
       "19866   대구   3  21        4    1255618      13.792650  43.166667       10.5   \n",
       "19867   대전   5  23        2     759431      10.719473  54.136364       14.2   \n",
       "19868   경북  11  12        3    1345200      21.171796  77.572523       13.0   \n",
       "19869   제주   1  22        1     291639      15.969401  69.151515        7.0   \n",
       "\n",
       "            avg_ps  diff_hum    pm10_7b  avg_age  min_temp  frequency  \n",
       "0      1021.800000      54.0  15.625000     41.6       3.1        0.0  \n",
       "1      1010.350000      55.0  43.726190     41.2      13.7        1.0  \n",
       "2      1024.564286      64.0  50.974537     42.2      -6.9        3.0  \n",
       "3      1020.600000      65.0  45.331092     41.4      10.0        2.0  \n",
       "4      1006.200000      50.0  33.968521     39.9      21.0        1.0  \n",
       "...            ...       ...        ...      ...       ...        ...  \n",
       "19865  1006.350000      25.0  11.650000     38.9      26.0        1.0  \n",
       "19866  1020.000000      64.0  42.598685     41.1       2.5        0.0  \n",
       "19867  1012.300000      53.0  58.950000     38.1      13.7        2.0  \n",
       "19868  1030.790476      45.0  58.179159     45.0       4.0        1.0  \n",
       "19869  1019.050000      35.0  56.145833     40.4       5.0        1.0  \n",
       "\n",
       "[19870 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb4eaeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_ee467_row8_col1, #T_ee467_row15_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_ee467\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ee467_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_ee467_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ee467_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_ee467_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ee467_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_ee467_row1_col1\" class=\"data row1 col1\" >frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ee467_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_ee467_row2_col1\" class=\"data row2 col1\" >Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ee467_row3_col0\" class=\"data row3 col0\" >Data shape</td>\n",
       "      <td id=\"T_ee467_row3_col1\" class=\"data row3 col1\" >(19870, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ee467_row4_col0\" class=\"data row4 col0\" >Train data shape</td>\n",
       "      <td id=\"T_ee467_row4_col1\" class=\"data row4 col1\" >(13908, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ee467_row5_col0\" class=\"data row5 col0\" >Test data shape</td>\n",
       "      <td id=\"T_ee467_row5_col1\" class=\"data row5 col1\" >(5962, 11)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_ee467_row6_col0\" class=\"data row6 col0\" >Numeric features</td>\n",
       "      <td id=\"T_ee467_row6_col1\" class=\"data row6 col1\" >12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_ee467_row7_col0\" class=\"data row7 col0\" >Categorical features</td>\n",
       "      <td id=\"T_ee467_row7_col1\" class=\"data row7 col1\" >3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_ee467_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_ee467_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_ee467_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_ee467_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_ee467_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_ee467_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_ee467_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_ee467_row11_col1\" class=\"data row11 col1\" >constant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_ee467_row12_col0\" class=\"data row12 col0\" >Maximum one-hot encoding</td>\n",
       "      <td id=\"T_ee467_row12_col1\" class=\"data row12 col1\" >5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_ee467_row13_col0\" class=\"data row13 col0\" >Encoding method</td>\n",
       "      <td id=\"T_ee467_row13_col1\" class=\"data row13 col1\" >None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_ee467_row14_col0\" class=\"data row14 col0\" >Low variance threshold</td>\n",
       "      <td id=\"T_ee467_row14_col1\" class=\"data row14 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_ee467_row15_col0\" class=\"data row15 col0\" >Remove multicollinearity</td>\n",
       "      <td id=\"T_ee467_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_ee467_row16_col0\" class=\"data row16 col0\" >Multicollinearity threshold</td>\n",
       "      <td id=\"T_ee467_row16_col1\" class=\"data row16 col1\" >0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_ee467_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_ee467_row17_col1\" class=\"data row17 col1\" >KFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_ee467_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_ee467_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_ee467_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_ee467_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_ee467_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_ee467_row20_col1\" class=\"data row20 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_ee467_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_ee467_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_ee467_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_ee467_row22_col1\" class=\"data row22 col1\" >reg-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ee467_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_ee467_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_ee467_row23_col1\" class=\"data row23 col1\" >fd51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11c9e1100>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 자동으로 데이터 유형 지정 \n",
    "from pycaret.regression import *\n",
    "female_data_s = setup(female_data, target = 'frequency', session_id=123, categorical_features=['area','mm','weekday',\n",
    "#                                                                                                'heat_wave',\n",
    "#                                                                                                 'cold_wave'\n",
    "                                                                                              ],\n",
    "          remove_multicollinearity = True, multicollinearity_threshold = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf4e898b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_39cd1 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_39cd1_row0_col0, #T_39cd1_row0_col1, #T_39cd1_row0_col5, #T_39cd1_row0_col6, #T_39cd1_row1_col0, #T_39cd1_row1_col1, #T_39cd1_row1_col2, #T_39cd1_row1_col3, #T_39cd1_row1_col5, #T_39cd1_row1_col6, #T_39cd1_row2_col0, #T_39cd1_row2_col1, #T_39cd1_row2_col2, #T_39cd1_row2_col3, #T_39cd1_row2_col5, #T_39cd1_row2_col6, #T_39cd1_row3_col0, #T_39cd1_row3_col1, #T_39cd1_row3_col2, #T_39cd1_row3_col3, #T_39cd1_row3_col5, #T_39cd1_row3_col6, #T_39cd1_row4_col0, #T_39cd1_row4_col1, #T_39cd1_row4_col2, #T_39cd1_row4_col3, #T_39cd1_row4_col4, #T_39cd1_row4_col5, #T_39cd1_row4_col6, #T_39cd1_row5_col0, #T_39cd1_row5_col1, #T_39cd1_row5_col2, #T_39cd1_row5_col3, #T_39cd1_row5_col4, #T_39cd1_row5_col5, #T_39cd1_row5_col6, #T_39cd1_row6_col0, #T_39cd1_row6_col2, #T_39cd1_row6_col3, #T_39cd1_row6_col4, #T_39cd1_row6_col6, #T_39cd1_row7_col0, #T_39cd1_row7_col1, #T_39cd1_row7_col2, #T_39cd1_row7_col3, #T_39cd1_row7_col4, #T_39cd1_row7_col5, #T_39cd1_row7_col6, #T_39cd1_row8_col0, #T_39cd1_row8_col1, #T_39cd1_row8_col2, #T_39cd1_row8_col3, #T_39cd1_row8_col4, #T_39cd1_row8_col5, #T_39cd1_row8_col6, #T_39cd1_row9_col0, #T_39cd1_row9_col1, #T_39cd1_row9_col2, #T_39cd1_row9_col3, #T_39cd1_row9_col4, #T_39cd1_row9_col5, #T_39cd1_row9_col6, #T_39cd1_row10_col0, #T_39cd1_row10_col1, #T_39cd1_row10_col2, #T_39cd1_row10_col3, #T_39cd1_row10_col4, #T_39cd1_row10_col5, #T_39cd1_row10_col6, #T_39cd1_row11_col0, #T_39cd1_row11_col1, #T_39cd1_row11_col2, #T_39cd1_row11_col3, #T_39cd1_row11_col4, #T_39cd1_row11_col5, #T_39cd1_row12_col0, #T_39cd1_row12_col1, #T_39cd1_row12_col2, #T_39cd1_row12_col3, #T_39cd1_row12_col4, #T_39cd1_row12_col5, #T_39cd1_row12_col6, #T_39cd1_row13_col0, #T_39cd1_row13_col1, #T_39cd1_row13_col2, #T_39cd1_row13_col3, #T_39cd1_row13_col4, #T_39cd1_row13_col5, #T_39cd1_row13_col6, #T_39cd1_row14_col0, #T_39cd1_row14_col1, #T_39cd1_row14_col2, #T_39cd1_row14_col3, #T_39cd1_row14_col4, #T_39cd1_row14_col5, #T_39cd1_row14_col6, #T_39cd1_row15_col0, #T_39cd1_row15_col1, #T_39cd1_row15_col2, #T_39cd1_row15_col3, #T_39cd1_row15_col4, #T_39cd1_row15_col5, #T_39cd1_row15_col6, #T_39cd1_row16_col0, #T_39cd1_row16_col1, #T_39cd1_row16_col2, #T_39cd1_row16_col3, #T_39cd1_row16_col4, #T_39cd1_row16_col5, #T_39cd1_row16_col6, #T_39cd1_row17_col0, #T_39cd1_row17_col1, #T_39cd1_row17_col2, #T_39cd1_row17_col3, #T_39cd1_row17_col4, #T_39cd1_row17_col5, #T_39cd1_row17_col6 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_39cd1_row0_col2, #T_39cd1_row0_col3, #T_39cd1_row0_col4, #T_39cd1_row1_col4, #T_39cd1_row2_col4, #T_39cd1_row3_col4, #T_39cd1_row6_col1, #T_39cd1_row6_col5, #T_39cd1_row11_col6 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_39cd1_row0_col7, #T_39cd1_row1_col7, #T_39cd1_row2_col7, #T_39cd1_row3_col7, #T_39cd1_row4_col7, #T_39cd1_row5_col7, #T_39cd1_row6_col7, #T_39cd1_row7_col7, #T_39cd1_row8_col7, #T_39cd1_row9_col7, #T_39cd1_row10_col7, #T_39cd1_row11_col7, #T_39cd1_row12_col7, #T_39cd1_row13_col7, #T_39cd1_row14_col7, #T_39cd1_row16_col7, #T_39cd1_row17_col7 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_39cd1_row15_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_39cd1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_39cd1_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_39cd1_level0_col1\" class=\"col_heading level0 col1\" >MAE</th>\n",
       "      <th id=\"T_39cd1_level0_col2\" class=\"col_heading level0 col2\" >MSE</th>\n",
       "      <th id=\"T_39cd1_level0_col3\" class=\"col_heading level0 col3\" >RMSE</th>\n",
       "      <th id=\"T_39cd1_level0_col4\" class=\"col_heading level0 col4\" >R2</th>\n",
       "      <th id=\"T_39cd1_level0_col5\" class=\"col_heading level0 col5\" >RMSLE</th>\n",
       "      <th id=\"T_39cd1_level0_col6\" class=\"col_heading level0 col6\" >MAPE</th>\n",
       "      <th id=\"T_39cd1_level0_col7\" class=\"col_heading level0 col7\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row0\" class=\"row_heading level0 row0\" >br</th>\n",
       "      <td id=\"T_39cd1_row0_col0\" class=\"data row0 col0\" >Bayesian Ridge</td>\n",
       "      <td id=\"T_39cd1_row0_col1\" class=\"data row0 col1\" >0.9098</td>\n",
       "      <td id=\"T_39cd1_row0_col2\" class=\"data row0 col2\" >1.5221</td>\n",
       "      <td id=\"T_39cd1_row0_col3\" class=\"data row0 col3\" >1.2333</td>\n",
       "      <td id=\"T_39cd1_row0_col4\" class=\"data row0 col4\" >0.4398</td>\n",
       "      <td id=\"T_39cd1_row0_col5\" class=\"data row0 col5\" >0.4881</td>\n",
       "      <td id=\"T_39cd1_row0_col6\" class=\"data row0 col6\" >0.4572</td>\n",
       "      <td id=\"T_39cd1_row0_col7\" class=\"data row0 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_39cd1_row1_col0\" class=\"data row1 col0\" >Linear Regression</td>\n",
       "      <td id=\"T_39cd1_row1_col1\" class=\"data row1 col1\" >0.9100</td>\n",
       "      <td id=\"T_39cd1_row1_col2\" class=\"data row1 col2\" >1.5222</td>\n",
       "      <td id=\"T_39cd1_row1_col3\" class=\"data row1 col3\" >1.2334</td>\n",
       "      <td id=\"T_39cd1_row1_col4\" class=\"data row1 col4\" >0.4398</td>\n",
       "      <td id=\"T_39cd1_row1_col5\" class=\"data row1 col5\" >0.4882</td>\n",
       "      <td id=\"T_39cd1_row1_col6\" class=\"data row1 col6\" >0.4576</td>\n",
       "      <td id=\"T_39cd1_row1_col7\" class=\"data row1 col7\" >0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row2\" class=\"row_heading level0 row2\" >ridge</th>\n",
       "      <td id=\"T_39cd1_row2_col0\" class=\"data row2 col0\" >Ridge Regression</td>\n",
       "      <td id=\"T_39cd1_row2_col1\" class=\"data row2 col1\" >0.9100</td>\n",
       "      <td id=\"T_39cd1_row2_col2\" class=\"data row2 col2\" >1.5222</td>\n",
       "      <td id=\"T_39cd1_row2_col3\" class=\"data row2 col3\" >1.2334</td>\n",
       "      <td id=\"T_39cd1_row2_col4\" class=\"data row2 col4\" >0.4398</td>\n",
       "      <td id=\"T_39cd1_row2_col5\" class=\"data row2 col5\" >0.4882</td>\n",
       "      <td id=\"T_39cd1_row2_col6\" class=\"data row2 col6\" >0.4576</td>\n",
       "      <td id=\"T_39cd1_row2_col7\" class=\"data row2 col7\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row3\" class=\"row_heading level0 row3\" >lar</th>\n",
       "      <td id=\"T_39cd1_row3_col0\" class=\"data row3 col0\" >Least Angle Regression</td>\n",
       "      <td id=\"T_39cd1_row3_col1\" class=\"data row3 col1\" >0.9100</td>\n",
       "      <td id=\"T_39cd1_row3_col2\" class=\"data row3 col2\" >1.5222</td>\n",
       "      <td id=\"T_39cd1_row3_col3\" class=\"data row3 col3\" >1.2334</td>\n",
       "      <td id=\"T_39cd1_row3_col4\" class=\"data row3 col4\" >0.4398</td>\n",
       "      <td id=\"T_39cd1_row3_col5\" class=\"data row3 col5\" >0.4882</td>\n",
       "      <td id=\"T_39cd1_row3_col6\" class=\"data row3 col6\" >0.4576</td>\n",
       "      <td id=\"T_39cd1_row3_col7\" class=\"data row3 col7\" >0.0180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row4\" class=\"row_heading level0 row4\" >omp</th>\n",
       "      <td id=\"T_39cd1_row4_col0\" class=\"data row4 col0\" >Orthogonal Matching Pursuit</td>\n",
       "      <td id=\"T_39cd1_row4_col1\" class=\"data row4 col1\" >0.9086</td>\n",
       "      <td id=\"T_39cd1_row4_col2\" class=\"data row4 col2\" >1.5596</td>\n",
       "      <td id=\"T_39cd1_row4_col3\" class=\"data row4 col3\" >1.2484</td>\n",
       "      <td id=\"T_39cd1_row4_col4\" class=\"data row4 col4\" >0.4261</td>\n",
       "      <td id=\"T_39cd1_row4_col5\" class=\"data row4 col5\" >0.4897</td>\n",
       "      <td id=\"T_39cd1_row4_col6\" class=\"data row4 col6\" >0.4452</td>\n",
       "      <td id=\"T_39cd1_row4_col7\" class=\"data row4 col7\" >0.0230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row5\" class=\"row_heading level0 row5\" >et</th>\n",
       "      <td id=\"T_39cd1_row5_col0\" class=\"data row5 col0\" >Extra Trees Regressor</td>\n",
       "      <td id=\"T_39cd1_row5_col1\" class=\"data row5 col1\" >0.9180</td>\n",
       "      <td id=\"T_39cd1_row5_col2\" class=\"data row5 col2\" >1.5723</td>\n",
       "      <td id=\"T_39cd1_row5_col3\" class=\"data row5 col3\" >1.2535</td>\n",
       "      <td id=\"T_39cd1_row5_col4\" class=\"data row5 col4\" >0.4213</td>\n",
       "      <td id=\"T_39cd1_row5_col5\" class=\"data row5 col5\" >0.4946</td>\n",
       "      <td id=\"T_39cd1_row5_col6\" class=\"data row5 col6\" >0.4450</td>\n",
       "      <td id=\"T_39cd1_row5_col7\" class=\"data row5 col7\" >0.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row6\" class=\"row_heading level0 row6\" >huber</th>\n",
       "      <td id=\"T_39cd1_row6_col0\" class=\"data row6 col0\" >Huber Regressor</td>\n",
       "      <td id=\"T_39cd1_row6_col1\" class=\"data row6 col1\" >0.9022</td>\n",
       "      <td id=\"T_39cd1_row6_col2\" class=\"data row6 col2\" >1.5754</td>\n",
       "      <td id=\"T_39cd1_row6_col3\" class=\"data row6 col3\" >1.2546</td>\n",
       "      <td id=\"T_39cd1_row6_col4\" class=\"data row6 col4\" >0.4204</td>\n",
       "      <td id=\"T_39cd1_row6_col5\" class=\"data row6 col5\" >0.4819</td>\n",
       "      <td id=\"T_39cd1_row6_col6\" class=\"data row6 col6\" >0.4496</td>\n",
       "      <td id=\"T_39cd1_row6_col7\" class=\"data row6 col7\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row7\" class=\"row_heading level0 row7\" >lightgbm</th>\n",
       "      <td id=\"T_39cd1_row7_col0\" class=\"data row7 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_39cd1_row7_col1\" class=\"data row7 col1\" >0.9460</td>\n",
       "      <td id=\"T_39cd1_row7_col2\" class=\"data row7 col2\" >1.6288</td>\n",
       "      <td id=\"T_39cd1_row7_col3\" class=\"data row7 col3\" >1.2757</td>\n",
       "      <td id=\"T_39cd1_row7_col4\" class=\"data row7 col4\" >0.4008</td>\n",
       "      <td id=\"T_39cd1_row7_col5\" class=\"data row7 col5\" >0.5136</td>\n",
       "      <td id=\"T_39cd1_row7_col6\" class=\"data row7 col6\" >0.4202</td>\n",
       "      <td id=\"T_39cd1_row7_col7\" class=\"data row7 col7\" >0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row8\" class=\"row_heading level0 row8\" >rf</th>\n",
       "      <td id=\"T_39cd1_row8_col0\" class=\"data row8 col0\" >Random Forest Regressor</td>\n",
       "      <td id=\"T_39cd1_row8_col1\" class=\"data row8 col1\" >0.9166</td>\n",
       "      <td id=\"T_39cd1_row8_col2\" class=\"data row8 col2\" >1.6894</td>\n",
       "      <td id=\"T_39cd1_row8_col3\" class=\"data row8 col3\" >1.2989</td>\n",
       "      <td id=\"T_39cd1_row8_col4\" class=\"data row8 col4\" >0.3786</td>\n",
       "      <td id=\"T_39cd1_row8_col5\" class=\"data row8 col5\" >0.5234</td>\n",
       "      <td id=\"T_39cd1_row8_col6\" class=\"data row8 col6\" >0.4552</td>\n",
       "      <td id=\"T_39cd1_row8_col7\" class=\"data row8 col7\" >0.3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row9\" class=\"row_heading level0 row9\" >gbr</th>\n",
       "      <td id=\"T_39cd1_row9_col0\" class=\"data row9 col0\" >Gradient Boosting Regressor</td>\n",
       "      <td id=\"T_39cd1_row9_col1\" class=\"data row9 col1\" >0.9935</td>\n",
       "      <td id=\"T_39cd1_row9_col2\" class=\"data row9 col2\" >1.6913</td>\n",
       "      <td id=\"T_39cd1_row9_col3\" class=\"data row9 col3\" >1.3000</td>\n",
       "      <td id=\"T_39cd1_row9_col4\" class=\"data row9 col4\" >0.3778</td>\n",
       "      <td id=\"T_39cd1_row9_col5\" class=\"data row9 col5\" >0.5322</td>\n",
       "      <td id=\"T_39cd1_row9_col6\" class=\"data row9 col6\" >0.4230</td>\n",
       "      <td id=\"T_39cd1_row9_col7\" class=\"data row9 col7\" >0.2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_39cd1_row10_col0\" class=\"data row10 col0\" >Decision Tree Regressor</td>\n",
       "      <td id=\"T_39cd1_row10_col1\" class=\"data row10 col1\" >0.9265</td>\n",
       "      <td id=\"T_39cd1_row10_col2\" class=\"data row10 col2\" >1.7607</td>\n",
       "      <td id=\"T_39cd1_row10_col3\" class=\"data row10 col3\" >1.3249</td>\n",
       "      <td id=\"T_39cd1_row10_col4\" class=\"data row10 col4\" >0.3526</td>\n",
       "      <td id=\"T_39cd1_row10_col5\" class=\"data row10 col5\" >0.5349</td>\n",
       "      <td id=\"T_39cd1_row10_col6\" class=\"data row10 col6\" >0.4679</td>\n",
       "      <td id=\"T_39cd1_row10_col7\" class=\"data row10 col7\" >0.0260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row11\" class=\"row_heading level0 row11\" >en</th>\n",
       "      <td id=\"T_39cd1_row11_col0\" class=\"data row11 col0\" >Elastic Net</td>\n",
       "      <td id=\"T_39cd1_row11_col1\" class=\"data row11 col1\" >1.0604</td>\n",
       "      <td id=\"T_39cd1_row11_col2\" class=\"data row11 col2\" >1.9791</td>\n",
       "      <td id=\"T_39cd1_row11_col3\" class=\"data row11 col3\" >1.4061</td>\n",
       "      <td id=\"T_39cd1_row11_col4\" class=\"data row11 col4\" >0.2728</td>\n",
       "      <td id=\"T_39cd1_row11_col5\" class=\"data row11 col5\" >0.5559</td>\n",
       "      <td id=\"T_39cd1_row11_col6\" class=\"data row11 col6\" >0.3903</td>\n",
       "      <td id=\"T_39cd1_row11_col7\" class=\"data row11 col7\" >0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row12\" class=\"row_heading level0 row12\" >ada</th>\n",
       "      <td id=\"T_39cd1_row12_col0\" class=\"data row12 col0\" >AdaBoost Regressor</td>\n",
       "      <td id=\"T_39cd1_row12_col1\" class=\"data row12 col1\" >1.2091</td>\n",
       "      <td id=\"T_39cd1_row12_col2\" class=\"data row12 col2\" >2.1516</td>\n",
       "      <td id=\"T_39cd1_row12_col3\" class=\"data row12 col3\" >1.4611</td>\n",
       "      <td id=\"T_39cd1_row12_col4\" class=\"data row12 col4\" >0.2092</td>\n",
       "      <td id=\"T_39cd1_row12_col5\" class=\"data row12 col5\" >0.6410</td>\n",
       "      <td id=\"T_39cd1_row12_col6\" class=\"data row12 col6\" >0.5979</td>\n",
       "      <td id=\"T_39cd1_row12_col7\" class=\"data row12 col7\" >0.0880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row13\" class=\"row_heading level0 row13\" >lasso</th>\n",
       "      <td id=\"T_39cd1_row13_col0\" class=\"data row13 col0\" >Lasso Regression</td>\n",
       "      <td id=\"T_39cd1_row13_col1\" class=\"data row13 col1\" >1.1842</td>\n",
       "      <td id=\"T_39cd1_row13_col2\" class=\"data row13 col2\" >2.4214</td>\n",
       "      <td id=\"T_39cd1_row13_col3\" class=\"data row13 col3\" >1.5551</td>\n",
       "      <td id=\"T_39cd1_row13_col4\" class=\"data row13 col4\" >0.1106</td>\n",
       "      <td id=\"T_39cd1_row13_col5\" class=\"data row13 col5\" >0.6087</td>\n",
       "      <td id=\"T_39cd1_row13_col6\" class=\"data row13 col6\" >0.4243</td>\n",
       "      <td id=\"T_39cd1_row13_col7\" class=\"data row13 col7\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row14\" class=\"row_heading level0 row14\" >llar</th>\n",
       "      <td id=\"T_39cd1_row14_col0\" class=\"data row14 col0\" >Lasso Least Angle Regression</td>\n",
       "      <td id=\"T_39cd1_row14_col1\" class=\"data row14 col1\" >1.2601</td>\n",
       "      <td id=\"T_39cd1_row14_col2\" class=\"data row14 col2\" >2.7238</td>\n",
       "      <td id=\"T_39cd1_row14_col3\" class=\"data row14 col3\" >1.6496</td>\n",
       "      <td id=\"T_39cd1_row14_col4\" class=\"data row14 col4\" >-0.0010</td>\n",
       "      <td id=\"T_39cd1_row14_col5\" class=\"data row14 col5\" >0.6434</td>\n",
       "      <td id=\"T_39cd1_row14_col6\" class=\"data row14 col6\" >0.4491</td>\n",
       "      <td id=\"T_39cd1_row14_col7\" class=\"data row14 col7\" >0.0220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_39cd1_row15_col0\" class=\"data row15 col0\" >Dummy Regressor</td>\n",
       "      <td id=\"T_39cd1_row15_col1\" class=\"data row15 col1\" >1.2601</td>\n",
       "      <td id=\"T_39cd1_row15_col2\" class=\"data row15 col2\" >2.7238</td>\n",
       "      <td id=\"T_39cd1_row15_col3\" class=\"data row15 col3\" >1.6496</td>\n",
       "      <td id=\"T_39cd1_row15_col4\" class=\"data row15 col4\" >-0.0010</td>\n",
       "      <td id=\"T_39cd1_row15_col5\" class=\"data row15 col5\" >0.6434</td>\n",
       "      <td id=\"T_39cd1_row15_col6\" class=\"data row15 col6\" >0.4491</td>\n",
       "      <td id=\"T_39cd1_row15_col7\" class=\"data row15 col7\" >0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row16\" class=\"row_heading level0 row16\" >knn</th>\n",
       "      <td id=\"T_39cd1_row16_col0\" class=\"data row16 col0\" >K Neighbors Regressor</td>\n",
       "      <td id=\"T_39cd1_row16_col1\" class=\"data row16 col1\" >1.2258</td>\n",
       "      <td id=\"T_39cd1_row16_col2\" class=\"data row16 col2\" >2.7731</td>\n",
       "      <td id=\"T_39cd1_row16_col3\" class=\"data row16 col3\" >1.6644</td>\n",
       "      <td id=\"T_39cd1_row16_col4\" class=\"data row16 col4\" >-0.0192</td>\n",
       "      <td id=\"T_39cd1_row16_col5\" class=\"data row16 col5\" >0.6397</td>\n",
       "      <td id=\"T_39cd1_row16_col6\" class=\"data row16 col6\" >0.5481</td>\n",
       "      <td id=\"T_39cd1_row16_col7\" class=\"data row16 col7\" >0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_39cd1_level0_row17\" class=\"row_heading level0 row17\" >par</th>\n",
       "      <td id=\"T_39cd1_row17_col0\" class=\"data row17 col0\" >Passive Aggressive Regressor</td>\n",
       "      <td id=\"T_39cd1_row17_col1\" class=\"data row17 col1\" >1.6110</td>\n",
       "      <td id=\"T_39cd1_row17_col2\" class=\"data row17 col2\" >4.1919</td>\n",
       "      <td id=\"T_39cd1_row17_col3\" class=\"data row17 col3\" >1.9226</td>\n",
       "      <td id=\"T_39cd1_row17_col4\" class=\"data row17 col4\" >-0.5667</td>\n",
       "      <td id=\"T_39cd1_row17_col5\" class=\"data row17 col5\" >0.7520</td>\n",
       "      <td id=\"T_39cd1_row17_col6\" class=\"data row17 col6\" >0.8927</td>\n",
       "      <td id=\"T_39cd1_row17_col7\" class=\"data row17 col7\" >0.0230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1573a7490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/85 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2eda1_row10_col0, #T_2eda1_row10_col1, #T_2eda1_row10_col2, #T_2eda1_row10_col3, #T_2eda1_row10_col4, #T_2eda1_row10_col5 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2eda1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2eda1_level0_col0\" class=\"col_heading level0 col0\" >MAE</th>\n",
       "      <th id=\"T_2eda1_level0_col1\" class=\"col_heading level0 col1\" >MSE</th>\n",
       "      <th id=\"T_2eda1_level0_col2\" class=\"col_heading level0 col2\" >RMSE</th>\n",
       "      <th id=\"T_2eda1_level0_col3\" class=\"col_heading level0 col3\" >R2</th>\n",
       "      <th id=\"T_2eda1_level0_col4\" class=\"col_heading level0 col4\" >RMSLE</th>\n",
       "      <th id=\"T_2eda1_level0_col5\" class=\"col_heading level0 col5\" >MAPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2eda1_row0_col0\" class=\"data row0 col0\" >0.8687</td>\n",
       "      <td id=\"T_2eda1_row0_col1\" class=\"data row0 col1\" >1.3879</td>\n",
       "      <td id=\"T_2eda1_row0_col2\" class=\"data row0 col2\" >1.1781</td>\n",
       "      <td id=\"T_2eda1_row0_col3\" class=\"data row0 col3\" >0.4340</td>\n",
       "      <td id=\"T_2eda1_row0_col4\" class=\"data row0 col4\" >0.4925</td>\n",
       "      <td id=\"T_2eda1_row0_col5\" class=\"data row0 col5\" >0.4217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2eda1_row1_col0\" class=\"data row1 col0\" >0.9364</td>\n",
       "      <td id=\"T_2eda1_row1_col1\" class=\"data row1 col1\" >1.6215</td>\n",
       "      <td id=\"T_2eda1_row1_col2\" class=\"data row1 col2\" >1.2734</td>\n",
       "      <td id=\"T_2eda1_row1_col3\" class=\"data row1 col3\" >0.4245</td>\n",
       "      <td id=\"T_2eda1_row1_col4\" class=\"data row1 col4\" >0.4967</td>\n",
       "      <td id=\"T_2eda1_row1_col5\" class=\"data row1 col5\" >0.4531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2eda1_row2_col0\" class=\"data row2 col0\" >0.8851</td>\n",
       "      <td id=\"T_2eda1_row2_col1\" class=\"data row2 col1\" >1.5017</td>\n",
       "      <td id=\"T_2eda1_row2_col2\" class=\"data row2 col2\" >1.2254</td>\n",
       "      <td id=\"T_2eda1_row2_col3\" class=\"data row2 col3\" >0.4494</td>\n",
       "      <td id=\"T_2eda1_row2_col4\" class=\"data row2 col4\" >0.4748</td>\n",
       "      <td id=\"T_2eda1_row2_col5\" class=\"data row2 col5\" >0.4437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2eda1_row3_col0\" class=\"data row3 col0\" >0.8992</td>\n",
       "      <td id=\"T_2eda1_row3_col1\" class=\"data row3 col1\" >1.5170</td>\n",
       "      <td id=\"T_2eda1_row3_col2\" class=\"data row3 col2\" >1.2317</td>\n",
       "      <td id=\"T_2eda1_row3_col3\" class=\"data row3 col3\" >0.4634</td>\n",
       "      <td id=\"T_2eda1_row3_col4\" class=\"data row3 col4\" >0.4856</td>\n",
       "      <td id=\"T_2eda1_row3_col5\" class=\"data row3 col5\" >0.4193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2eda1_row4_col0\" class=\"data row4 col0\" >0.9204</td>\n",
       "      <td id=\"T_2eda1_row4_col1\" class=\"data row4 col1\" >1.5330</td>\n",
       "      <td id=\"T_2eda1_row4_col2\" class=\"data row4 col2\" >1.2381</td>\n",
       "      <td id=\"T_2eda1_row4_col3\" class=\"data row4 col3\" >0.4099</td>\n",
       "      <td id=\"T_2eda1_row4_col4\" class=\"data row4 col4\" >0.4892</td>\n",
       "      <td id=\"T_2eda1_row4_col5\" class=\"data row4 col5\" >0.4832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2eda1_row5_col0\" class=\"data row5 col0\" >0.9386</td>\n",
       "      <td id=\"T_2eda1_row5_col1\" class=\"data row5 col1\" >1.6177</td>\n",
       "      <td id=\"T_2eda1_row5_col2\" class=\"data row5 col2\" >1.2719</td>\n",
       "      <td id=\"T_2eda1_row5_col3\" class=\"data row5 col3\" >0.4786</td>\n",
       "      <td id=\"T_2eda1_row5_col4\" class=\"data row5 col4\" >0.4957</td>\n",
       "      <td id=\"T_2eda1_row5_col5\" class=\"data row5 col5\" >0.4518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2eda1_row6_col0\" class=\"data row6 col0\" >0.9255</td>\n",
       "      <td id=\"T_2eda1_row6_col1\" class=\"data row6 col1\" >1.6245</td>\n",
       "      <td id=\"T_2eda1_row6_col2\" class=\"data row6 col2\" >1.2746</td>\n",
       "      <td id=\"T_2eda1_row6_col3\" class=\"data row6 col3\" >0.4106</td>\n",
       "      <td id=\"T_2eda1_row6_col4\" class=\"data row6 col4\" >0.4864</td>\n",
       "      <td id=\"T_2eda1_row6_col5\" class=\"data row6 col5\" >0.4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2eda1_row7_col0\" class=\"data row7 col0\" >0.8867</td>\n",
       "      <td id=\"T_2eda1_row7_col1\" class=\"data row7 col1\" >1.5041</td>\n",
       "      <td id=\"T_2eda1_row7_col2\" class=\"data row7 col2\" >1.2264</td>\n",
       "      <td id=\"T_2eda1_row7_col3\" class=\"data row7 col3\" >0.4593</td>\n",
       "      <td id=\"T_2eda1_row7_col4\" class=\"data row7 col4\" >0.4670</td>\n",
       "      <td id=\"T_2eda1_row7_col5\" class=\"data row7 col5\" >0.4494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_2eda1_row8_col0\" class=\"data row8 col0\" >0.8919</td>\n",
       "      <td id=\"T_2eda1_row8_col1\" class=\"data row8 col1\" >1.4136</td>\n",
       "      <td id=\"T_2eda1_row8_col2\" class=\"data row8 col2\" >1.1889</td>\n",
       "      <td id=\"T_2eda1_row8_col3\" class=\"data row8 col3\" >0.4446</td>\n",
       "      <td id=\"T_2eda1_row8_col4\" class=\"data row8 col4\" >0.4908</td>\n",
       "      <td id=\"T_2eda1_row8_col5\" class=\"data row8 col5\" >0.4632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_2eda1_row9_col0\" class=\"data row9 col0\" >0.9206</td>\n",
       "      <td id=\"T_2eda1_row9_col1\" class=\"data row9 col1\" >1.5137</td>\n",
       "      <td id=\"T_2eda1_row9_col2\" class=\"data row9 col2\" >1.2303</td>\n",
       "      <td id=\"T_2eda1_row9_col3\" class=\"data row9 col3\" >0.4190</td>\n",
       "      <td id=\"T_2eda1_row9_col4\" class=\"data row9 col4\" >0.4914</td>\n",
       "      <td id=\"T_2eda1_row9_col5\" class=\"data row9 col5\" >0.4723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_2eda1_row10_col0\" class=\"data row10 col0\" >0.9073</td>\n",
       "      <td id=\"T_2eda1_row10_col1\" class=\"data row10 col1\" >1.5235</td>\n",
       "      <td id=\"T_2eda1_row10_col2\" class=\"data row10 col2\" >1.2339</td>\n",
       "      <td id=\"T_2eda1_row10_col3\" class=\"data row10 col3\" >0.4393</td>\n",
       "      <td id=\"T_2eda1_row10_col4\" class=\"data row10 col4\" >0.4870</td>\n",
       "      <td id=\"T_2eda1_row10_col5\" class=\"data row10 col5\" >0.4529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2eda1_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_2eda1_row11_col0\" class=\"data row11 col0\" >0.0228</td>\n",
       "      <td id=\"T_2eda1_row11_col1\" class=\"data row11 col1\" >0.0776</td>\n",
       "      <td id=\"T_2eda1_row11_col2\" class=\"data row11 col2\" >0.0316</td>\n",
       "      <td id=\"T_2eda1_row11_col3\" class=\"data row11 col3\" >0.0224</td>\n",
       "      <td id=\"T_2eda1_row11_col4\" class=\"data row11 col4\" >0.0089</td>\n",
       "      <td id=\"T_2eda1_row11_col5\" class=\"data row11 col5\" >0.0198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11d7a78b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이창훈\n",
    "female_best_model_5 = compare_models(sort='RMSE', n_select = 5)\n",
    "model_female = blend_models(female_best_model_5)\n",
    "\n",
    "# 이이슬\n",
    "# female_best_model_5 = compare_models(sort='RMSE', n_select = 5)\n",
    "# female_tuned_top5 = [tune_model(i, optimize = 'RMSE', n_iter=10) for i in female_best_model_5]\n",
    "# model_female = stack_models(female_tuned_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8bdf7",
   "metadata": {},
   "source": [
    "# 2016년 예측(여자)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b431e888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>763170</td>\n",
       "      <td>17.989439</td>\n",
       "      <td>83.354839</td>\n",
       "      <td>3.845070</td>\n",
       "      <td>1027.575000</td>\n",
       "      <td>33.314706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.3</td>\n",
       "      <td>-0.271831</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5922058</td>\n",
       "      <td>10.605097</td>\n",
       "      <td>65.448276</td>\n",
       "      <td>5.413208</td>\n",
       "      <td>1025.875000</td>\n",
       "      <td>28.227586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.7</td>\n",
       "      <td>3.124528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1644010</td>\n",
       "      <td>15.039264</td>\n",
       "      <td>74.583333</td>\n",
       "      <td>3.112821</td>\n",
       "      <td>1023.921429</td>\n",
       "      <td>19.566667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.5</td>\n",
       "      <td>4.946154</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1343468</td>\n",
       "      <td>19.192046</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>3.338182</td>\n",
       "      <td>1026.137500</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.923636</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2011</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>737858</td>\n",
       "      <td>10.984634</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>1022.900000</td>\n",
       "      <td>23.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.6</td>\n",
       "      <td>4.740000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31581</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>952025</td>\n",
       "      <td>25.227174</td>\n",
       "      <td>65.555094</td>\n",
       "      <td>13.700000</td>\n",
       "      <td>1030.607692</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>33.635000</td>\n",
       "      <td>46.4</td>\n",
       "      <td>-4.700000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31582</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>937286</td>\n",
       "      <td>21.548385</td>\n",
       "      <td>72.161486</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>1030.586667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>52.149758</td>\n",
       "      <td>44.7</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31583</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>319052</td>\n",
       "      <td>16.552474</td>\n",
       "      <td>60.569257</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1029.900000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>28.460474</td>\n",
       "      <td>41.9</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31584</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1031962</td>\n",
       "      <td>19.719912</td>\n",
       "      <td>75.118243</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>1030.100000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>71.473958</td>\n",
       "      <td>43.5</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31585</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>788385</td>\n",
       "      <td>17.822003</td>\n",
       "      <td>72.665541</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1031.400000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>60.829167</td>\n",
       "      <td>43.2</td>\n",
       "      <td>-6.800000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31586 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  yyyy  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  \\\n",
       "0       강원  2011  12   1        3     763170      17.989439  83.354839   \n",
       "1       경기  2011  12   1        3    5922058      10.605097  65.448276   \n",
       "2       경남  2011  12   1        3    1644010      15.039264  74.583333   \n",
       "3       경북  2011  12   1        3    1343468      19.192046  81.000000   \n",
       "4       광주  2011  12   1        3     737858      10.984634  89.000000   \n",
       "...    ...   ...  ..  ..      ...        ...            ...        ...   \n",
       "31581   전남  2016  12  31        5     952025      25.227174  65.555094   \n",
       "31582   전북  2016  12  31        5     937286      21.548385  72.161486   \n",
       "31583   제주  2016  12  31        5     319052      16.552474  60.569257   \n",
       "31584   충남  2016  12  31        5    1031962      19.719912  75.118243   \n",
       "31585   충북  2016  12  31        5     788385      17.822003  72.665541   \n",
       "\n",
       "       diff_temp       avg_ps   diff_hum    pm10_7b  avg_age  min_temp  \\\n",
       "0       3.845070  1027.575000  33.314706        NaN     42.3 -0.271831   \n",
       "1       5.413208  1025.875000  28.227586        NaN     37.7  3.124528   \n",
       "2       3.112821  1023.921429  19.566667        NaN     40.5  4.946154   \n",
       "3       3.338182  1026.137500  28.800000        NaN     43.1  2.923636   \n",
       "4       3.840000  1022.900000  23.066667        NaN     37.6  4.740000   \n",
       "...          ...          ...        ...        ...      ...       ...   \n",
       "31581  13.700000  1030.607692  49.000000  33.635000     46.4 -4.700000   \n",
       "31582  14.500000  1030.586667  42.000000  52.149758     44.7 -7.000000   \n",
       "31583   8.000000  1029.900000  31.000000  28.460474     41.9  2.500000   \n",
       "31584  11.700000  1030.100000  41.000000  71.473958     43.5 -4.000000   \n",
       "31585  12.000000  1031.400000  35.000000  60.829167     43.2 -6.800000   \n",
       "\n",
       "       frequency  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "31581        NaN  \n",
       "31582        NaN  \n",
       "31583        NaN  \n",
       "31584        NaN  \n",
       "31585        NaN  \n",
       "\n",
       "[31586 rows x 15 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_female = pd.read_csv('./hospital_female_0802_test3.csv', encoding='cp949') #이 csv 파일은 2016년 데이터까지 포함한 것\n",
    "# dataset3.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "test_female = test_female[['area','yyyy','mm','dd','weekday','total_pop','elderly_ratio',\n",
    "                          'avg_hum','diff_temp','avg_ps','diff_hum','pm10_7b',\n",
    "                          'avg_age','min_temp','frequency']]\n",
    "#     ['area','yyyy','dd','mm','weekday','heat_wave','cold_wave','total_pop','elderly_ratio',\n",
    "#           'pm10_7b','diff_hum','diff_temp','avg_ps',\n",
    "#           'avg_age', 'min_max_ps','frequency']]\n",
    "test_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96cbbc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>768008</td>\n",
       "      <td>19.916980</td>\n",
       "      <td>58.196911</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1030.230000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.954167</td>\n",
       "      <td>44.5</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6229840</td>\n",
       "      <td>12.194759</td>\n",
       "      <td>70.844595</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1031.633333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.487621</td>\n",
       "      <td>39.7</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1669577</td>\n",
       "      <td>16.753405</td>\n",
       "      <td>52.099421</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1031.175000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.128224</td>\n",
       "      <td>42.4</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1344592</td>\n",
       "      <td>21.253882</td>\n",
       "      <td>57.314554</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1030.309524</td>\n",
       "      <td>66.0</td>\n",
       "      <td>38.389385</td>\n",
       "      <td>45.1</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>742807</td>\n",
       "      <td>13.091826</td>\n",
       "      <td>62.837838</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1032.200000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>39.7</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>952025</td>\n",
       "      <td>25.227174</td>\n",
       "      <td>65.555094</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1030.607692</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.635000</td>\n",
       "      <td>46.4</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>937286</td>\n",
       "      <td>21.548385</td>\n",
       "      <td>72.161486</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1030.586667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.149758</td>\n",
       "      <td>44.7</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>319052</td>\n",
       "      <td>16.552474</td>\n",
       "      <td>60.569257</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1029.900000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.460474</td>\n",
       "      <td>41.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1031962</td>\n",
       "      <td>19.719912</td>\n",
       "      <td>75.118243</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1030.100000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.473958</td>\n",
       "      <td>43.5</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>788385</td>\n",
       "      <td>17.822003</td>\n",
       "      <td>72.665541</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1031.400000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.829167</td>\n",
       "      <td>43.2</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  \\\n",
       "0      강원  2016   1   1        4     768008      19.916980  58.196911   \n",
       "1      경기  2016   1   1        4    6229840      12.194759  70.844595   \n",
       "2      경남  2016   1   1        4    1669577      16.753405  52.099421   \n",
       "3      경북  2016   1   1        4    1344592      21.253882  57.314554   \n",
       "4      광주  2016   1   1        4     742807      13.091826  62.837838   \n",
       "...   ...   ...  ..  ..      ...        ...            ...        ...   \n",
       "6217   전남  2016  12  31        5     952025      25.227174  65.555094   \n",
       "6218   전북  2016  12  31        5     937286      21.548385  72.161486   \n",
       "6219   제주  2016  12  31        5     319052      16.552474  60.569257   \n",
       "6220   충남  2016  12  31        5    1031962      19.719912  75.118243   \n",
       "6221   충북  2016  12  31        5     788385      17.822003  72.665541   \n",
       "\n",
       "      diff_temp       avg_ps  diff_hum    pm10_7b  avg_age  min_temp  \\\n",
       "0          18.9  1030.230000      73.0  61.954167     44.5      -8.9   \n",
       "1          12.1  1031.633333      45.0  42.487621     39.7      -6.9   \n",
       "2          17.7  1031.175000      79.0  29.128224     42.4      -7.0   \n",
       "3          20.0  1030.309524      66.0  38.389385     45.1     -10.0   \n",
       "4          10.0  1032.200000      40.0  20.475000     39.7      -2.0   \n",
       "...         ...          ...       ...        ...      ...       ...   \n",
       "6217       13.7  1030.607692      49.0  33.635000     46.4      -4.7   \n",
       "6218       14.5  1030.586667      42.0  52.149758     44.7      -7.0   \n",
       "6219        8.0  1029.900000      31.0  28.460474     41.9       2.5   \n",
       "6220       11.7  1030.100000      41.0  71.473958     43.5      -4.0   \n",
       "6221       12.0  1031.400000      35.0  60.829167     43.2      -6.8   \n",
       "\n",
       "      frequency  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "6217        NaN  \n",
       "6218        NaN  \n",
       "6219        NaN  \n",
       "6220        NaN  \n",
       "6221        NaN  \n",
       "\n",
       "[6222 rows x 15 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_female2 = test_female[test_female['yyyy'].astype(str).str.contains('2016')].reset_index(drop=True)#2016년만 추출\n",
    "test_female2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60692307",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_female3 = test_female2.drop(columns=['frequency','yyyy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87bd398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "female_final_model = finalize_model(model_female)\n",
    "prediction_female = predict_model(female_final_model, data = test_female3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e656a2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction_female['Label'] = prediction_female['Label'].round(0)\n",
    "# prediction_female[['Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3506c5",
   "metadata": {},
   "source": [
    "# 남자 여자 예측 데이터 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccf22e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>weekday</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>elderly_ratio</th>\n",
       "      <th>avg_hum</th>\n",
       "      <th>diff_temp</th>\n",
       "      <th>avg_ps</th>\n",
       "      <th>diff_hum</th>\n",
       "      <th>pm10_7b</th>\n",
       "      <th>avg_age</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>781185</td>\n",
       "      <td>14.022671</td>\n",
       "      <td>58.196911</td>\n",
       "      <td>18.9</td>\n",
       "      <td>1030.230000</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.954167</td>\n",
       "      <td>41.4</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6306634</td>\n",
       "      <td>8.966558</td>\n",
       "      <td>70.844595</td>\n",
       "      <td>12.1</td>\n",
       "      <td>1031.633333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>42.487621</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1695187</td>\n",
       "      <td>10.962802</td>\n",
       "      <td>52.099421</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1031.175000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.128224</td>\n",
       "      <td>39.3</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1356568</td>\n",
       "      <td>14.384461</td>\n",
       "      <td>57.314554</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1030.309524</td>\n",
       "      <td>66.0</td>\n",
       "      <td>38.389385</td>\n",
       "      <td>41.5</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>729995</td>\n",
       "      <td>9.572120</td>\n",
       "      <td>62.837838</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1032.200000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>37.4</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>951889</td>\n",
       "      <td>16.677050</td>\n",
       "      <td>65.555094</td>\n",
       "      <td>13.7</td>\n",
       "      <td>1030.607692</td>\n",
       "      <td>49.0</td>\n",
       "      <td>33.635000</td>\n",
       "      <td>42.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>927505</td>\n",
       "      <td>15.011563</td>\n",
       "      <td>72.161486</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1030.586667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>52.149758</td>\n",
       "      <td>41.4</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>322545</td>\n",
       "      <td>11.278426</td>\n",
       "      <td>60.569257</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1029.900000</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.460474</td>\n",
       "      <td>39.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>1064765</td>\n",
       "      <td>13.768860</td>\n",
       "      <td>75.118243</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1030.100000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>71.473958</td>\n",
       "      <td>40.7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>803240</td>\n",
       "      <td>12.472486</td>\n",
       "      <td>72.665541</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1031.400000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>60.829167</td>\n",
       "      <td>40.5</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd  weekday  total_pop  elderly_ratio    avg_hum  \\\n",
       "0      강원  2016   1   1        4     781185      14.022671  58.196911   \n",
       "1      경기  2016   1   1        4    6306634       8.966558  70.844595   \n",
       "2      경남  2016   1   1        4    1695187      10.962802  52.099421   \n",
       "3      경북  2016   1   1        4    1356568      14.384461  57.314554   \n",
       "4      광주  2016   1   1        4     729995       9.572120  62.837838   \n",
       "...   ...   ...  ..  ..      ...        ...            ...        ...   \n",
       "6217   전남  2016  12  31        5     951889      16.677050  65.555094   \n",
       "6218   전북  2016  12  31        5     927505      15.011563  72.161486   \n",
       "6219   제주  2016  12  31        5     322545      11.278426  60.569257   \n",
       "6220   충남  2016  12  31        5    1064765      13.768860  75.118243   \n",
       "6221   충북  2016  12  31        5     803240      12.472486  72.665541   \n",
       "\n",
       "      diff_temp       avg_ps  diff_hum    pm10_7b  avg_age  min_temp  \\\n",
       "0          18.9  1030.230000      73.0  61.954167     41.4      -8.9   \n",
       "1          12.1  1031.633333      45.0  42.487621     38.0      -6.9   \n",
       "2          17.7  1031.175000      79.0  29.128224     39.3      -7.0   \n",
       "3          20.0  1030.309524      66.0  38.389385     41.5     -10.0   \n",
       "4          10.0  1032.200000      40.0  20.475000     37.4      -2.0   \n",
       "...         ...          ...       ...        ...      ...       ...   \n",
       "6217       13.7  1030.607692      49.0  33.635000     42.6      -4.7   \n",
       "6218       14.5  1030.586667      42.0  52.149758     41.4      -7.0   \n",
       "6219        8.0  1029.900000      31.0  28.460474     39.2       2.5   \n",
       "6220       11.7  1030.100000      41.0  71.473958     40.7      -4.0   \n",
       "6221       12.0  1031.400000      35.0  60.829167     40.5      -6.8   \n",
       "\n",
       "      frequency  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "...         ...  \n",
       "6217        NaN  \n",
       "6218        NaN  \n",
       "6219        NaN  \n",
       "6220        NaN  \n",
       "6221        NaN  \n",
       "\n",
       "[6222 rows x 15 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_male2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a779975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>Label</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.019175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770378</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.077180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.776797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>-0.085399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.744145</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.651508</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd     Label  sex\n",
       "0      강원  2016   1   1  1.206999    1\n",
       "1      경기  2016   1   1  4.728955    1\n",
       "2      경남  2016   1   1  2.090019    1\n",
       "3      경북  2016   1   1  2.019175    1\n",
       "4      광주  2016   1   1  0.770378    1\n",
       "...   ...   ...  ..  ..       ...  ...\n",
       "6217   전남  2016  12  31  1.077180    1\n",
       "6218   전북  2016  12  31  0.776797    1\n",
       "6219   제주  2016  12  31 -0.085399    1\n",
       "6220   충남  2016  12  31  0.744145    1\n",
       "6221   충북  2016  12  31  0.651508    1\n",
       "\n",
       "[6222 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap_male = pd.concat([test_male2[['area','yyyy','mm','dd']], prediction_male['Label']], axis=1)\n",
    "hap_male['sex'] = 1\n",
    "hap_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7601e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>Label</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009395</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.480691</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.108461</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.961473</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856757</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.427070</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.201757</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.800623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.732411</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd     Label  sex\n",
       "0      강원  2016   1   1  1.009395    2\n",
       "1      경기  2016   1   1  4.480691    2\n",
       "2      경남  2016   1   1  2.108461    2\n",
       "3      경북  2016   1   1  1.961473    2\n",
       "4      광주  2016   1   1  0.856757    2\n",
       "...   ...   ...  ..  ..       ...  ...\n",
       "6217   전남  2016  12  31  1.427070    2\n",
       "6218   전북  2016  12  31  1.201757    2\n",
       "6219   제주  2016  12  31  0.015232    2\n",
       "6220   충남  2016  12  31  0.800623    2\n",
       "6221   충북  2016  12  31  0.732411    2\n",
       "\n",
       "[6222 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap_female = pd.concat([test_female2[['area','yyyy','mm','dd']], prediction_female['Label']], axis=1)\n",
    "hap_female['sex'] = 2\n",
    "hap_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ad89890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경북</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>광주</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전남</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전북</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>제주</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충남</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충북</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         yyyymmdd area  sex  frequency\n",
       "0      2016-01-01   강원    1        NaN\n",
       "1      2016-01-01   경기    1        NaN\n",
       "2      2016-01-01   경남    1        NaN\n",
       "3      2016-01-01   경북    1        NaN\n",
       "4      2016-01-01   광주    1        NaN\n",
       "...           ...  ...  ...        ...\n",
       "12439  2016-12-31   전남    2        NaN\n",
       "12440  2016-12-31   전북    2        NaN\n",
       "12441  2016-12-31   제주    2        NaN\n",
       "12442  2016-12-31   충남    2        NaN\n",
       "12443  2016-12-31   충북    2        NaN\n",
       "\n",
       "[12444 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify = pd.read_csv('./edited_data/2-2_검증데이터셋.csv', encoding='cp949')\n",
    "verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21cb594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_male['yyyy'] = hap_male['yyyy'].astype('int')\n",
    "hap_male['mm'] = hap_male['mm'].astype('int')\n",
    "hap_male['dd'] = hap_male['dd'].astype('int')\n",
    "\n",
    "hap_female['yyyy'] = hap_female['yyyy'].astype('int')\n",
    "hap_female['mm'] = hap_female['mm'].astype('int')\n",
    "hap_female['dd'] = hap_female['dd'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2274081",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap_male['dateInt']=hap_male['yyyy'].astype(str) + hap_male['mm'].astype(str).str.zfill(2)+ hap_male['dd'].astype(str).str.zfill(2)\n",
    "hap_male['date'] = pd.to_datetime(hap_male['dateInt'], format='%Y%m%d')\n",
    "hap_male.drop(columns=['dateInt'], inplace=True)\n",
    "\n",
    "hap_female['dateInt']=hap_female['yyyy'].astype(str) + hap_female['mm'].astype(str).str.zfill(2)+ hap_female['dd'].astype(str).str.zfill(2)\n",
    "hap_female['date'] = pd.to_datetime(hap_female['dateInt'], format='%Y%m%d')\n",
    "hap_female.drop(columns=['dateInt'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "431d4960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>Label</th>\n",
       "      <th>sex</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.009395</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.480691</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.108461</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.961473</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856757</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.427070</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.201757</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6219</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.800623</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6221</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.732411</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6222 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     area  yyyy  mm  dd     Label  sex       date\n",
       "0      강원  2016   1   1  1.009395    2 2016-01-01\n",
       "1      경기  2016   1   1  4.480691    2 2016-01-01\n",
       "2      경남  2016   1   1  2.108461    2 2016-01-01\n",
       "3      경북  2016   1   1  1.961473    2 2016-01-01\n",
       "4      광주  2016   1   1  0.856757    2 2016-01-01\n",
       "...   ...   ...  ..  ..       ...  ...        ...\n",
       "6217   전남  2016  12  31  1.427070    2 2016-12-31\n",
       "6218   전북  2016  12  31  1.201757    2 2016-12-31\n",
       "6219   제주  2016  12  31  0.015232    2 2016-12-31\n",
       "6220   충남  2016  12  31  0.800623    2 2016-12-31\n",
       "6221   충북  2016  12  31  0.732411    2 2016-12-31\n",
       "\n",
       "[6222 rows x 7 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap_male.sort_values(['date', 'area']).reset_index(drop=True)\n",
    "hap_female.sort_values(['date', 'area']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3d8408b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>yyyy</th>\n",
       "      <th>mm</th>\n",
       "      <th>dd</th>\n",
       "      <th>Label</th>\n",
       "      <th>sex</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>강원</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206999</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>경기</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728955</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>경남</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090019</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>경북</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.019175</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>광주</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770378</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>전남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.427070</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>전북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>1.201757</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>제주</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>충남</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.800623</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>충북</td>\n",
       "      <td>2016</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.732411</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      area  yyyy  mm  dd     Label  sex       date\n",
       "0       강원  2016   1   1  1.206999    1 2016-01-01\n",
       "1       경기  2016   1   1  4.728955    1 2016-01-01\n",
       "2       경남  2016   1   1  2.090019    1 2016-01-01\n",
       "3       경북  2016   1   1  2.019175    1 2016-01-01\n",
       "4       광주  2016   1   1  0.770378    1 2016-01-01\n",
       "...    ...   ...  ..  ..       ...  ...        ...\n",
       "12439   전남  2016  12  31  1.427070    2 2016-12-31\n",
       "12440   전북  2016  12  31  1.201757    2 2016-12-31\n",
       "12441   제주  2016  12  31  0.015232    2 2016-12-31\n",
       "12442   충남  2016  12  31  0.800623    2 2016-12-31\n",
       "12443   충북  2016  12  31  0.732411    2 2016-12-31\n",
       "\n",
       "[12444 rows x 7 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hap = pd.concat([hap_male, hap_female], axis=0).reset_index(drop=True)\n",
    "hap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6c3408b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경북</td>\n",
       "      <td>1</td>\n",
       "      <td>2.019175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>광주</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전남</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전북</td>\n",
       "      <td>2</td>\n",
       "      <td>1.201757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>제주</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충남</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충북</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         yyyymmdd area  sex  frequency\n",
       "0      2016-01-01   강원    1   1.206999\n",
       "1      2016-01-01   경기    1   4.728955\n",
       "2      2016-01-01   경남    1   2.090019\n",
       "3      2016-01-01   경북    1   2.019175\n",
       "4      2016-01-01   광주    1   0.770378\n",
       "...           ...  ...  ...        ...\n",
       "12439  2016-12-31   전남    2   1.427070\n",
       "12440  2016-12-31   전북    2   1.201757\n",
       "12441  2016-12-31   제주    2   0.015232\n",
       "12442  2016-12-31   충남    2   0.800623\n",
       "12443  2016-12-31   충북    2   0.732411\n",
       "\n",
       "[12444 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify['frequency'] = hap['Label']\n",
    "verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9041be08",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.loc[verify['frequency'] < 0, 'frequency'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "304f93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.to_csv('./220023_0807_5.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8875ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hap['date'] = hap['date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9a4432fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경북</td>\n",
       "      <td>1</td>\n",
       "      <td>2.019175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>광주</td>\n",
       "      <td>1</td>\n",
       "      <td>0.770378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전남</td>\n",
       "      <td>2</td>\n",
       "      <td>1.427070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>전북</td>\n",
       "      <td>2</td>\n",
       "      <td>1.201757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>제주</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충남</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충북</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         yyyymmdd area  sex  frequency\n",
       "0      2016-01-01   강원    1   1.206999\n",
       "1      2016-01-01   경기    1   4.728955\n",
       "2      2016-01-01   경남    1   2.090019\n",
       "3      2016-01-01   경북    1   2.019175\n",
       "4      2016-01-01   광주    1   0.770378\n",
       "...           ...  ...  ...        ...\n",
       "12439  2016-12-31   전남    2   1.427070\n",
       "12440  2016-12-31   전북    2   1.201757\n",
       "12441  2016-12-31   제주    2   0.015232\n",
       "12442  2016-12-31   충남    2   0.800623\n",
       "12443  2016-12-31   충북    2   0.732411\n",
       "\n",
       "[12444 rows x 4 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_ = verify.merge(hap, how='left', left_on = ['yyyymmdd','area','sex'], right_on = ['date','area','sex'])[['yyyymmdd','area','sex','Label']]\n",
    "verify_ = verify_.rename(columns = {'Label':'frequency'})\n",
    "verify_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "51b25b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yyyymmdd</th>\n",
       "      <th>area</th>\n",
       "      <th>sex</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>1</td>\n",
       "      <td>1.206999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>강원</td>\n",
       "      <td>2</td>\n",
       "      <td>1.009395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>1</td>\n",
       "      <td>4.728955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경기</td>\n",
       "      <td>2</td>\n",
       "      <td>4.480691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>경남</td>\n",
       "      <td>1</td>\n",
       "      <td>2.090019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>제주</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충남</td>\n",
       "      <td>1</td>\n",
       "      <td>0.744145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충남</td>\n",
       "      <td>2</td>\n",
       "      <td>0.800623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12442</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충북</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12443</th>\n",
       "      <td>2016-12-31</td>\n",
       "      <td>충북</td>\n",
       "      <td>2</td>\n",
       "      <td>0.732411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12444 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         yyyymmdd area  sex  frequency\n",
       "0      2016-01-01   강원    1   1.206999\n",
       "1      2016-01-01   강원    2   1.009395\n",
       "2      2016-01-01   경기    1   4.728955\n",
       "3      2016-01-01   경기    2   4.480691\n",
       "4      2016-01-01   경남    1   2.090019\n",
       "...           ...  ...  ...        ...\n",
       "12439  2016-12-31   제주    2   0.015232\n",
       "12440  2016-12-31   충남    1   0.744145\n",
       "12441  2016-12-31   충남    2   0.800623\n",
       "12442  2016-12-31   충북    1   0.651508\n",
       "12443  2016-12-31   충북    2   0.732411\n",
       "\n",
       "[12444 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_.sort_values(['yyyymmdd', 'area']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ffacedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_.to_csv('./220023_0807_6.csv', encoding='cp949', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f808cd7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(female_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "574ce88a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(female_final_model, plot='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "89186542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), OrthogonalMatchingPursuit())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n",
      "/Users/ichanghun/miniforge3/envs/tens2/lib/python3.9/site-packages/sklearn/linear_model/_base.py:133: FutureWarning: The default of 'normalize' will be set to False in version 1.2 and deprecated in version 1.4.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), Lars())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(female_final_model, plot='learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "675fb2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53a5fd71422945218b7b7fab28ea84c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(female_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5e90d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    24837.000000\n",
       "mean         1.416475\n",
       "std          1.655311\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max         13.000000\n",
       "Name: frequency, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_df['frequency'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4d478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
